<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[itimor的Book]]></title>
      <url>/2018/01/02/idnex/</url>
      <content type="html"><![CDATA[<p><strong>郑重说明</strong>：本人无耻的盗用的vuejs的主题，觉得它的样式非常好看，特此拿来给自己做技术方面的文档笔记，记录一下鸟问题。</p>
]]></content>
      
        
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <url>/index.html</url>
      <content type="html"></content>
    </entry>
    
    <entry>
      <title></title>
      <url>/menu/index.html</url>
      <content type="html"></content>
    </entry>
    
    <entry>
      <title><![CDATA[贡献者]]></title>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<h2 id="Guide-翻译贡献"><a href="#Guide-翻译贡献" class="headerlink" title="Guide 翻译贡献"></a>Guide 翻译贡献</h2><h3 id="Essentials-基础"><a href="#Essentials-基础" class="headerlink" title="Essentials  基础"></a>Essentials  基础</h3><table>
<thead>
<tr>
<th>序号</th>
<th>对应文档文件名</th>
<th>中文标题</th>
<th>翻译贡献者</th>
<th>校对主要贡献者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>installation.md</td>
<td>安装</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a> <a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
</tr>
<tr>
<td>2</td>
<td>index.md</td>
<td>介绍</td>
<td><a href="https://github.com/hijiangtao" target="_blank" rel="noopener">hijiangtao</a></td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a> <a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a></td>
</tr>
<tr>
<td>3</td>
<td>instance.md</td>
<td>实例</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a> <a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a></td>
</tr>
<tr>
<td>4</td>
<td>syntax.md</td>
<td>模板语法</td>
<td><a href="https://github.com/daix6" target="_blank" rel="noopener">daix6</a></td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
</tr>
<tr>
<td>5</td>
<td>computed.md</td>
<td>计算属 性</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a> <a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
</tr>
<tr>
<td>6</td>
<td>class-and-style.md</td>
<td>Class 与 Style 绑定</td>
<td><a href="https://github.com/595074187" target="_blank" rel="noopener">595074187</a></td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
</tr>
<tr>
<td>7</td>
<td>conditional.md</td>
<td>条件渲染</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/hgcoder" target="_blank" rel="noopener">hgcoder</a></td>
</tr>
<tr>
<td>8</td>
<td>list.md</td>
<td>列表渲染</td>
<td><a href="https://github.com/tingtien" target="_blank" rel="noopener">tingtien</a></td>
<td><a href="https://github.com/hgcoder" target="_blank" rel="noopener">hgcoder</a></td>
</tr>
<tr>
<td>9</td>
<td>events.md</td>
<td>事件处理器</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/yangzj1992" target="_blank" rel="noopener">yangzj1992</a></td>
</tr>
<tr>
<td>10</td>
<td>forms.md</td>
<td>表单控件绑定</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/yangzj1992" target="_blank" rel="noopener">yangzj1992</a></td>
</tr>
<tr>
<td>11</td>
<td>components.md</td>
<td>组件</td>
<td><a href="https://github.com/ezreally" target="_blank" rel="noopener">ezreally</a></td>
<td><a href="https://github.com/cuiyongjian" target="_blank" rel="noopener">cuiyongjian</a></td>
</tr>
</tbody>
</table>
<h3 id="Advanced-进阶"><a href="#Advanced-进阶" class="headerlink" title="Advanced  进阶"></a>Advanced  进阶</h3><table>
<thead>
<tr>
<th>序号</th>
<th>对应文档文件名</th>
<th>中文标题</th>
<th>翻译贡献者</th>
<th>校对主要贡献者</th>
</tr>
</thead>
<tbody>
<tr>
<td>12</td>
<td>transitions.md</td>
<td>过渡: 进入, 离开, 和 列表</td>
<td><a href="https://github.com/hilongjw" target="_blank" rel="noopener">awe</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a> <a href="https://github.com/StoneQI" target="_blank" rel="noopener">StoneQI</a></td>
</tr>
<tr>
<td>13</td>
<td>transitioning-state.md</td>
<td>过渡状态</td>
<td><a href="https://github.com/hilongjw" target="_blank" rel="noopener">awe</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>14</td>
<td>render-function.md</td>
<td>Render 函数</td>
<td><a href="https://github.com/hilongjw" target="_blank" rel="noopener">awe</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>15</td>
<td>reactivity.md</td>
<td>深入响应式原理</td>
<td><a href="https://github.com/veaba" target="_blank" rel="noopener">veaba</a></td>
<td><a href="https://github.com/yangzj1992" target="_blank" rel="noopener">yangzj1992</a></td>
</tr>
<tr>
<td>16</td>
<td>custom-directive.md</td>
<td>自定义指令</td>
<td><a href="https://github.com/hurrytospring" target="_blank" rel="noopener">hurrytospring</a></td>
<td><a href="https://github.com/yangzj1992" target="_blank" rel="noopener">yangzj1992</a></td>
</tr>
<tr>
<td>17</td>
<td>mixins.md</td>
<td>混合</td>
<td><a href="https://github.com/hurrytospring" target="_blank" rel="noopener">hurrytospring</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>18</td>
<td>plugins.md</td>
<td>插件</td>
<td><a href="https://github.com/hgcoder" target="_blank" rel="noopener">hgcoder</a></td>
<td><a href="https://github.com/hgcoder" target="_blank" rel="noopener">hgcoder</a></td>
</tr>
<tr>
<td>19</td>
<td>single-file-components.md</td>
<td>单文件组件</td>
<td><a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a></td>
<td><a href="https://github.com/zhouzihanntu" target="_blank" rel="noopener">zhouzihanntu</a></td>
</tr>
<tr>
<td>20</td>
<td>routing.md</td>
<td>路由</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/mlyknown" target="_blank" rel="noopener">mlyknown</a></td>
</tr>
<tr>
<td>21</td>
<td>state-management.md</td>
<td>状态管理</td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
<td><a href="https://github.com/mlyknown" target="_blank" rel="noopener">mlyknown</a></td>
</tr>
<tr>
<td>22</td>
<td>unit-testing.md</td>
<td>单元测试</td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
<td><a href="https://github.com/mlyknown" target="_blank" rel="noopener">mlyknown</a></td>
</tr>
<tr>
<td>23</td>
<td>ssr.md</td>
<td>服务端渲染</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/yongbolv" target="_blank" rel="noopener">yongbolv</a></td>
</tr>
</tbody>
</table>
<h3 id="Migration-迁移"><a href="#Migration-迁移" class="headerlink" title="Migration  迁移"></a>Migration  迁移</h3><table>
<thead>
<tr>
<th>序号</th>
<th>对应文档文件名</th>
<th>中文标题</th>
<th>翻译贡献者</th>
<th>校对主要贡献者</th>
</tr>
</thead>
<tbody>
<tr>
<td>24</td>
<td>migration.md</td>
<td>1.x迁移</td>
<td><a href="https://github.com/hurrytospring" target="_blank" rel="noopener">hurrytospring</a></td>
<td><a href="https://github.com/yongbolv" target="_blank" rel="noopener">yongbolv</a></td>
</tr>
<tr>
<td>27</td>
<td>migration-vue-router.md</td>
<td>vue-router 0.7.x 迁移</td>
<td><a href="https://github.com/forzajuve10" target="_blank" rel="noopener">forzajuve10</a></td>
<td><a href="https://github.com/yizhixiaolongxia" target="_blank" rel="noopener">yizhixiaolongxia</a></td>
</tr>
</tbody>
</table>
<h3 id="Meta-更多"><a href="#Meta-更多" class="headerlink" title="Meta  更多"></a>Meta  更多</h3><table>
<thead>
<tr>
<th>序号</th>
<th>对应文档文件名</th>
<th>中文标题</th>
<th>翻译贡献者</th>
<th>校对主要贡献者</th>
</tr>
</thead>
<tbody>
<tr>
<td>25</td>
<td>comparison.md</td>
<td>对比其他框架</td>
<td><a href="https://github.com/yongbolv" target="_blank" rel="noopener">yongbolv</a></td>
<td><a href="https://github.com/yangzj1992" target="_blank" rel="noopener">yangzj1992</a></td>
</tr>
<tr>
<td>26</td>
<td>join.md</td>
<td>加入 Vue.js 社区</td>
<td><a href="https://github.com/daix6" target="_blank" rel="noopener">daix6</a></td>
<td><a href="https://github.com/zhouzihanntu" target="_blank" rel="noopener">zhouzihanntu</a></td>
</tr>
</tbody>
</table>
<h2 id="API翻译贡献"><a href="#API翻译贡献" class="headerlink" title="API翻译贡献"></a>API翻译贡献</h2><table>
<thead>
<tr>
<th>序号</th>
<th>对应小节名称</th>
<th>中文标题</th>
<th>翻译贡献者</th>
<th>校对主要贡献者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Global Config</td>
<td>全局配置</td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>2</td>
<td>Global API</td>
<td>全局 API</td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>3</td>
<td>Options / Data</td>
<td>选项 / 数据</td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>4</td>
<td>Options / DOM</td>
<td>选项 / DOM</td>
<td><a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>5</td>
<td>Options / Lifecycle Hooks</td>
<td>选项 / 生命周期钩子</td>
<td><a href="https://github.com/ATLgo" target="_blank" rel="noopener">ATLgo</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>6</td>
<td>Options / Assets</td>
<td>选项 / 资源</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>7</td>
<td>Options / Misc</td>
<td>选项 / 杂项</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>8</td>
<td>Instance Properties</td>
<td>实例属性</td>
<td><a href="https://github.com/coolzjy" target="_blank" rel="noopener">coolzjy</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>9</td>
<td>Instance Methods / Data</td>
<td>实例方法 / 数据</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>10</td>
<td>Instance Methods / Events</td>
<td>实例方法 / 事件</td>
<td><a href="https://github.com/mlyknown" target="_blank" rel="noopener">mlyknown</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>11</td>
<td>Instance Methods / Lifecycle</td>
<td>实例方法 / 生命周期</td>
<td><a href="https://github.com/mlyknown" target="_blank" rel="noopener">mlyknown</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>12</td>
<td>Directives</td>
<td>指令</td>
<td><a href="https://github.com/dingyiming" target="_blank" rel="noopener">dingyiming</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>13</td>
<td>Special Attributes</td>
<td>特殊元素</td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>14</td>
<td>Built-In Components</td>
<td>内置的组件</td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
<td><a href="https://github.com/bhnddowinf" target="_blank" rel="noopener">bhnddowinf</a></td>
</tr>
<tr>
<td>15</td>
<td>VNode Interface</td>
<td>VNode 接口</td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
</tr>
<tr>
<td>16</td>
<td>Server-Side Rendering</td>
<td>服务端渲染</td>
<td><a href="https://github.com/70data" target="_blank" rel="noopener">70data</a></td>
<td><a href="https://github.com/dear-lizhihua" target="_blank" rel="noopener">dear-lizhihua</a></td>
</tr>
</tbody>
</table>
<h2 id="示例翻译"><a href="#示例翻译" class="headerlink" title="示例翻译"></a>示例翻译</h2><p>翻译贡献者 ： <a href="https://github.com/lindazhang102" target="_blank" rel="noopener">lindazhang102</a></p>
<h2 id="感谢所有参与翻译的朋友们！"><a href="#感谢所有参与翻译的朋友们！" class="headerlink" title="感谢所有参与翻译的朋友们！"></a>感谢所有参与翻译的朋友们！</h2>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Pandas入门]]></title>
      <url>/ml/mllib/Pandas1.html</url>
      <content type="html"><![CDATA[<h2 id="Pandas介绍"><a href="#Pandas介绍" class="headerlink" title="Pandas介绍"></a>Pandas介绍</h2><p>pandas是Python在数据处理方面功能最为强大的扩展模块。在处理实际的金融数据时，一个条数据通常包含了多种类型的数据，例如，股票的代码是字符串，收盘价是浮点型，而成交量是整型等。在C++中可以实现为一个给定结构体作为单元的容器，如向量（vector，C++中的特定数据结构）。在Python中，pandas包含了高级的数据结构Series和DataFrame，使得在Python中处理数据变得非常方便、快速和简单。</p>
<h3 id="Numpy-和-Pandas-有什么不同"><a href="#Numpy-和-Pandas-有什么不同" class="headerlink" title="Numpy 和 Pandas 有什么不同"></a>Numpy 和 Pandas 有什么不同</h3><p>如果用 python 的列表和字典来作比较, 那么可以说 Numpy 是列表形式的，没有数值标签，而 Pandas 就是字典形式。Pandas是基于Numpy构建的，让Numpy为中心的应用变得更加简单。</p>
<p>pandas主要的两个数据结构是Series和DataFrame，随后两节将介绍如何由其他类型的数据结构得到这两种数据结构，或者自行创建这两种数据结构，我们先导入它们以及相关模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br></pre></td></tr></table></figure>
<h2 id="Pandas数据结构：Series"><a href="#Pandas数据结构：Series" class="headerlink" title="Pandas数据结构：Series"></a>Pandas数据结构：Series</h2><p>从一般意义上来讲，Series可以简单地被认为是一维的数组。Series和一维数组最主要的区别在于Series类型具有索引（index）。</p>
<h3 id="创建Series"><a href="#创建Series" class="headerlink" title="创建Series"></a>创建Series</h3><p>创建一个Series的基本格式是s = Series(data, index=index, name=name)，以下给出几个创建Series的例子。首先我们从数组创建Series：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: a = np.random.randn(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: a</span><br><span class="line">Out[<span class="number">19</span>]: array([<span class="number">-0.13907742</span>, <span class="number">-1.13472176</span>, <span class="number">-0.30952444</span>,  <span class="number">0.5945551</span> , <span class="number">-1.11253943</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">20</span>]: s = Series(a)</span><br><span class="line"></span><br><span class="line">In [<span class="number">21</span>]: s</span><br><span class="line">Out[<span class="number">21</span>]:</span><br><span class="line"><span class="number">0</span>   <span class="number">-0.139077</span></span><br><span class="line"><span class="number">1</span>   <span class="number">-1.134722</span></span><br><span class="line"><span class="number">2</span>   <span class="number">-0.309524</span></span><br><span class="line"><span class="number">3</span>    <span class="number">0.594555</span></span><br><span class="line"><span class="number">4</span>   <span class="number">-1.112539</span>s = pd.Series([<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>,np.nan,<span class="number">44</span>,<span class="number">1</span>])</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>由于我们没有为数据指定索引。于是会自动创建一个0到N-1（N为长度）的整数型索引。</p>
<p>可以在创建Series时添加index，并可使用Series.index查看具体的index。需要注意的一点是，当从数组创建Series时，若指定index，那么index长度要和data的长度一致：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">26</span>]: s = Series(np.random.randn(<span class="number">5</span>), index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: s</span><br><span class="line">Out[<span class="number">27</span>]:</span><br><span class="line">a    <span class="number">0.391180</span></span><br><span class="line">b   <span class="number">-0.909680</span></span><br><span class="line">c   <span class="number">-0.751830</span></span><br><span class="line">d   <span class="number">-0.628885</span></span><br><span class="line">e   <span class="number">-2.225025</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: s.index</span><br><span class="line">Out[<span class="number">28</span>]: Index([<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>], dtype=<span class="string">'object'</span>)</span><br></pre></td></tr></table></figure>
<p>创建Series的另一个可选项是name，可指定Series的名称，可用Series.name访问。在随后的DataFrame中，每一列的列名在该列被单独取出来时就成了Series的名称：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">29</span>]: s = Series(np.random.randn(<span class="number">5</span>), index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>], name=<span class="string">'my_series'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: s</span><br><span class="line">Out[<span class="number">30</span>]:</span><br><span class="line">a   <span class="number">-0.061299</span></span><br><span class="line">b    <span class="number">1.448393</span></span><br><span class="line">c   <span class="number">-2.871637</span></span><br><span class="line">d   <span class="number">-0.254603</span></span><br><span class="line">e   <span class="number">-0.970275</span></span><br><span class="line">Name: my_series, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">31</span>]: s.name</span><br><span class="line">Out[<span class="number">31</span>]: <span class="string">'my_series'</span></span><br></pre></td></tr></table></figure>
<p>Series还可以从字典（dict）创建：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">35</span>]: d = &#123;<span class="string">'a'</span>: <span class="number">0.</span>, <span class="string">'b'</span>: <span class="number">1</span>, <span class="string">'c'</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: s = Series(d)</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: s</span><br><span class="line">Out[<span class="number">37</span>]:</span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>让我们来看看使用字典创建Series时指定index的情形（index长度不必和字典相同）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">38</span>]: Series(d, index=[<span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'a'</span>])</span><br><span class="line">Out[<span class="number">38</span>]:</span><br><span class="line">b    <span class="number">1.0</span></span><br><span class="line">c    <span class="number">2.0</span></span><br><span class="line">d    NaN</span><br><span class="line">a    <span class="number">0.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>我们可以观察到两点：一是字典创建的Series，数据将按index的顺序重新排列；二是index长度可以和字典长度不一致，如果多了的话，pandas将自动为多余的index分配NaN（not a number，pandas中数据缺失的标准记号)，当然index少的话就截取部分的字典内容。</p>
<p>如果数据就是一个单一的变量，如数字4，那么Series将重复这个变量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">39</span>]: Series(<span class="number">4.</span>, index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>])</span><br><span class="line">Out[<span class="number">39</span>]:</span><br><span class="line">a    <span class="number">4.0</span></span><br><span class="line">b    <span class="number">4.0</span></span><br><span class="line">c    <span class="number">4.0</span></span><br><span class="line">d    <span class="number">4.0</span></span><br><span class="line">e    <span class="number">4.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<h3 id="Series数据的访问"><a href="#Series数据的访问" class="headerlink" title="Series数据的访问"></a>Series数据的访问</h3><p>访问Series数据可以和数组一样使用下标，也可以像字典一样使用索引，还可以使用一些条件过滤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">40</span>]: s = Series(np.random.randn(<span class="number">10</span>),index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>, <span class="string">'g'</span>, <span class="string">'h'</span>, <span class="string">'i'</span>, <span class="string">'j'</span>])</span><br><span class="line">    ...: s[<span class="number">0</span>]</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">40</span>]: <span class="number">1.6327010042454009</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: s[:<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">41</span>]:</span><br><span class="line">a    <span class="number">1.632701</span></span><br><span class="line">b   <span class="number">-0.808834</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">42</span>]: s[[<span class="number">2</span>,<span class="number">0</span>,<span class="number">4</span>]]</span><br><span class="line">Out[<span class="number">42</span>]:</span><br><span class="line">c   <span class="number">-1.708988</span></span><br><span class="line">a    <span class="number">1.632701</span></span><br><span class="line">e   <span class="number">-0.989622</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: s[[<span class="string">'e'</span>, <span class="string">'i'</span>]]</span><br><span class="line">Out[<span class="number">43</span>]:</span><br><span class="line">e   <span class="number">-0.989622</span></span><br><span class="line">i   <span class="number">-0.901893</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: s[s &gt; <span class="number">0.5</span>]</span><br><span class="line">Out[<span class="number">44</span>]:</span><br><span class="line">a    <span class="number">1.632701</span></span><br><span class="line">d    <span class="number">2.814273</span></span><br><span class="line">g    <span class="number">1.337555</span></span><br><span class="line">j    <span class="number">1.314560</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: <span class="string">'e'</span> <span class="keyword">in</span> s</span><br><span class="line">Out[<span class="number">45</span>]: <span class="keyword">True</span></span><br></pre></td></tr></table></figure>
<h2 id="Pandas数据结构：DataFrame"><a href="#Pandas数据结构：DataFrame" class="headerlink" title="Pandas数据结构：DataFrame"></a>Pandas数据结构：DataFrame</h2><p>在使用DataFrame之前，我们说明一下DataFrame的特性。DataFrame是将数个Series按列合并而成的二维数据结构，每一列单独取出来是一个Series，这和SQL数据库中取出的数据是很类似的。所以，按列对一个DataFrame进行处理更为方便，用户在编程时注意培养按列构建数据的思维。DataFrame的优势在于可以方便地处理不同类型的列，因此，就不要考虑如何对一个全是浮点数的DataFrame求逆之类的问题了，处理这种问题还是把数据存成NumPy的matrix类型比较便利一些。</p>
<h3 id="创建DataFrame"><a href="#创建DataFrame" class="headerlink" title="创建DataFrame"></a>创建DataFrame</h3><p>首先来看如何从字典创建DataFrame。DataFrame是一个二维的数据结构，是多个Series的集合体。我们先创建一个值是Series的字典，并转换为DataFrame：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">46</span>]: d = &#123;<span class="string">'one'</span>: Series([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>]), <span class="string">'two'</span>: Series([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>])&#125;</span><br><span class="line">    ...: df = DataFrame(d)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">47</span>]: df</span><br><span class="line">Out[<span class="number">47</span>]:</span><br><span class="line">   one  two</span><br><span class="line">a  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line">b  <span class="number">2.0</span>  <span class="number">2.0</span></span><br><span class="line">c  <span class="number">3.0</span>  <span class="number">3.0</span></span><br><span class="line">d  NaN  <span class="number">4.0</span></span><br></pre></td></tr></table></figure>
<p>可以指定所需的行和列，若字典中不含有对应的元素，则置为NaN：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: df = DataFrame(d, index=[<span class="string">'r'</span>, <span class="string">'d'</span>, <span class="string">'a'</span>], columns=[<span class="string">'two'</span>, <span class="string">'three'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: df</span><br><span class="line">Out[<span class="number">49</span>]:</span><br><span class="line">   two three</span><br><span class="line">r  NaN   NaN</span><br><span class="line">d  <span class="number">4.0</span>   NaN</span><br><span class="line">a  <span class="number">1.0</span>   NaN</span><br></pre></td></tr></table></figure></p>
<p>可以使用dataframe.index和dataframe.columns来查看DataFrame的行和列，dataframe.values则以数组的形式返回DataFrame的元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: df.index</span><br><span class="line">Out[<span class="number">50</span>]: Index([<span class="string">'r'</span>, <span class="string">'d'</span>, <span class="string">'a'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: df.columns</span><br><span class="line">Out[<span class="number">51</span>]: Index([<span class="string">'two'</span>, <span class="string">'three'</span>], dtype=<span class="string">'object'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: df.values</span><br><span class="line">Out[<span class="number">52</span>]:</span><br><span class="line">array([[nan, nan],</span><br><span class="line">       [<span class="number">4.0</span>, nan],</span><br><span class="line">       [<span class="number">1.0</span>, nan]], dtype=object)</span><br></pre></td></tr></table></figure>
<p>DataFrame也可以从值是数组的字典创建，但是各个数组的长度需要相同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">53</span>]: d = &#123;<span class="string">'one'</span>: [<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>], <span class="string">'two'</span>: [<span class="number">4.</span>, <span class="number">3.</span>, <span class="number">2.</span>, <span class="number">1.</span>]&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">54</span>]: df = DataFrame(d, index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: df</span><br><span class="line">Out[<span class="number">55</span>]:</span><br><span class="line">   one  two</span><br><span class="line">a  <span class="number">1.0</span>  <span class="number">4.0</span></span><br><span class="line">b  <span class="number">2.0</span>  <span class="number">3.0</span></span><br><span class="line">c  <span class="number">3.0</span>  <span class="number">2.0</span></span><br><span class="line">d  <span class="number">4.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<p>值非数组时，没有这一限制，并且缺失值补成NaN：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">56</span>]: d= [&#123;<span class="string">'a'</span>: <span class="number">1.6</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;, &#123;<span class="string">'a'</span>: <span class="number">3</span>, <span class="string">'b'</span>: <span class="number">6</span>, <span class="string">'c'</span>: <span class="number">9</span>&#125;]</span><br><span class="line">    ...: df = DataFrame(d)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">57</span>]: df</span><br><span class="line">Out[<span class="number">57</span>]:</span><br><span class="line">     a  b    c</span><br><span class="line"><span class="number">0</span>  <span class="number">1.6</span>  <span class="number">2</span>  NaN</span><br><span class="line"><span class="number">1</span>  <span class="number">3.0</span>  <span class="number">6</span>  <span class="number">9.0</span></span><br></pre></td></tr></table></figure>
<p>在实际处理数据时，有时需要创建一个空的DataFrame，可以这么做<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">58</span>]: df = DataFrame()</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: df</span><br><span class="line">Out[<span class="number">59</span>]:</span><br><span class="line">Empty DataFrame</span><br><span class="line">Columns: []</span><br><span class="line">Index: []</span><br></pre></td></tr></table></figure></p>
<p>另一种创建DataFrame的方法十分有用，那就是使用concat函数基于Series或者DataFrame创建一个DataFrame</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">62</span>]: a = Series(range(<span class="number">5</span>))</span><br><span class="line">    ...: b = Series(np.linspace(<span class="number">4</span>, <span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line">    ...: df = pd.concat([a, b], axis=<span class="number">1</span>)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">63</span>]: df</span><br><span class="line">Out[<span class="number">63</span>]:</span><br><span class="line">   <span class="number">0</span>     <span class="number">1</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>   <span class="number">4.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1</span>   <span class="number">8.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2</span>  <span class="number">12.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">3</span>  <span class="number">16.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">4</span>  <span class="number">20.0</span></span><br></pre></td></tr></table></figure>
<p>其中的axis=1表示按列进行合并，axis=0表示按行合并，并且，Series都处理成一列，所以这里如果选axis=0的话，将得到一个10×1的DataFrame。下面这个例子展示了如何按行合并DataFrame成一个大的DataFrame：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: df = DataFrame()</span><br><span class="line">    ...: index = [<span class="string">'alpha'</span>, <span class="string">'beta'</span>, <span class="string">'gamma'</span>, <span class="string">'delta'</span>, <span class="string">'eta'</span>]</span><br><span class="line">    ...: <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    ...:     a = DataFrame([np.linspace(i, <span class="number">5</span>*i, <span class="number">5</span>)], index=[index[i]])</span><br><span class="line">    ...:     df = pd.concat([df, a], axis=<span class="number">0</span>)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">65</span>]: df</span><br><span class="line">Out[<span class="number">65</span>]:</span><br><span class="line">         <span class="number">0</span>    <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span></span><br><span class="line">alpha  <span class="number">0.0</span>  <span class="number">0.0</span>   <span class="number">0.0</span>   <span class="number">0.0</span>   <span class="number">0.0</span></span><br><span class="line">beta   <span class="number">1.0</span>  <span class="number">2.0</span>   <span class="number">3.0</span>   <span class="number">4.0</span>   <span class="number">5.0</span></span><br><span class="line">gamma  <span class="number">2.0</span>  <span class="number">4.0</span>   <span class="number">6.0</span>   <span class="number">8.0</span>  <span class="number">10.0</span></span><br><span class="line">delta  <span class="number">3.0</span>  <span class="number">6.0</span>   <span class="number">9.0</span>  <span class="number">12.0</span>  <span class="number">15.0</span></span><br><span class="line">eta    <span class="number">4.0</span>  <span class="number">8.0</span>  <span class="number">12.0</span>  <span class="number">16.0</span>  <span class="number">20.0</span></span><br></pre></td></tr></table></figure>
<h3 id="DataFrame数据的访问"><a href="#DataFrame数据的访问" class="headerlink" title="DataFrame数据的访问"></a>DataFrame数据的访问</h3><p>首先，再次强调一下DataFrame是以列作为操作的基础的，全部操作都想象成先从DataFrame里取一列，再从这个Series取元素即可。可以用datafrae.column_name选取列，也可以使用dataframe[]操作选取列，我们可以马上发现前一种方法只能选取一列，而后一种方法可以选择多列。若DataFrame没有列名，[]可以使用非负整数，也就是“下标”选取列；若有列名，则必须使用列名选取，另外datafrae.column_name在没有列名的时候是无效的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">66</span>]: df[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">66</span>]:</span><br><span class="line">alpha    <span class="number">0.0</span></span><br><span class="line">beta     <span class="number">2.0</span></span><br><span class="line">gamma    <span class="number">4.0</span></span><br><span class="line">delta    <span class="number">6.0</span></span><br><span class="line">eta      <span class="number">8.0</span></span><br><span class="line">Name: <span class="number">1</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: type(df[<span class="number">1</span>])</span><br><span class="line">Out[<span class="number">67</span>]: pandas.core.series.Series</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">71</span>]: df.columns = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: df[<span class="string">'b'</span>]</span><br><span class="line">Out[<span class="number">72</span>]:</span><br><span class="line">alpha    <span class="number">0.0</span></span><br><span class="line">beta     <span class="number">2.0</span></span><br><span class="line">gamma    <span class="number">4.0</span></span><br><span class="line">delta    <span class="number">6.0</span></span><br><span class="line">eta      <span class="number">8.0</span></span><br><span class="line">Name: b, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">78</span>]: df.b</span><br><span class="line">Out[<span class="number">78</span>]:</span><br><span class="line">alpha    <span class="number">0.0</span></span><br><span class="line">beta     <span class="number">2.0</span></span><br><span class="line">gamma    <span class="number">4.0</span></span><br><span class="line">delta    <span class="number">6.0</span></span><br><span class="line">eta      <span class="number">8.0</span></span><br><span class="line">Name: b, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: df[[<span class="string">'a'</span>,<span class="string">'b'</span>]]</span><br><span class="line">Out[<span class="number">79</span>]:</span><br><span class="line">         a    b</span><br><span class="line">alpha  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line">beta   <span class="number">1.0</span>  <span class="number">2.0</span></span><br><span class="line">gamma  <span class="number">2.0</span>  <span class="number">4.0</span></span><br><span class="line">delta  <span class="number">3.0</span>  <span class="number">6.0</span></span><br><span class="line">eta    <span class="number">4.0</span>  <span class="number">8.0</span></span><br></pre></td></tr></table></figure>
<p>以上代码使用了dataframe.columns为DataFrame赋列名，并且我们看到单独取一列出来，其数据结构显示的是Series，取两列及两列以上的结果仍然是DataFrame。访问特定的元素可以如Series一样使用下标或者是索引:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">84</span>]: df.b[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">84</span>]: <span class="number">4.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">85</span>]: df.b.gamma</span><br><span class="line">Out[<span class="number">85</span>]: <span class="number">4.0</span></span><br></pre></td></tr></table></figure>
<p>若需要选取行，可以使用dataframe.iloc按下标选取，或者使用dataframe.loc按索引选取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">86</span>]: df.iloc[<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">86</span>]:</span><br><span class="line">a    <span class="number">1.0</span></span><br><span class="line">b    <span class="number">2.0</span></span><br><span class="line">c    <span class="number">3.0</span></span><br><span class="line">d    <span class="number">4.0</span></span><br><span class="line">e    <span class="number">5.0</span></span><br><span class="line">Name: beta, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">87</span>]: df.loc[<span class="string">'beta'</span>]</span><br><span class="line">Out[<span class="number">87</span>]:</span><br><span class="line">a    <span class="number">1.0</span></span><br><span class="line">b    <span class="number">2.0</span></span><br><span class="line">c    <span class="number">3.0</span></span><br><span class="line">d    <span class="number">4.0</span></span><br><span class="line">e    <span class="number">5.0</span></span><br><span class="line">Name: beta, dtype: float64</span><br></pre></td></tr></table></figure>
<p>选取行还可以使用切片的方式或者是布尔类型的向量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">88</span>]: df[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Out[<span class="number">88</span>]:</span><br><span class="line">         a    b    c    d     e</span><br><span class="line">beta   <span class="number">1.0</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  <span class="number">4.0</span>   <span class="number">5.0</span></span><br><span class="line">gamma  <span class="number">2.0</span>  <span class="number">4.0</span>  <span class="number">6.0</span>  <span class="number">8.0</span>  <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: bool_vec = [<span class="keyword">True</span>, <span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">True</span>, <span class="keyword">False</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">90</span>]: df[bool_vec]</span><br><span class="line">Out[<span class="number">90</span>]:</span><br><span class="line">         a    b    c     d     e</span><br><span class="line">alpha  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>   <span class="number">0.0</span>   <span class="number">0.0</span></span><br><span class="line">gamma  <span class="number">2.0</span>  <span class="number">4.0</span>  <span class="number">6.0</span>   <span class="number">8.0</span>  <span class="number">10.0</span></span><br><span class="line">delta  <span class="number">3.0</span>  <span class="number">6.0</span>  <span class="number">9.0</span>  <span class="number">12.0</span>  <span class="number">15.0</span></span><br></pre></td></tr></table></figure>
<p>行列组合起来选取数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">91</span>]: df[[<span class="string">'b'</span>, <span class="string">'d'</span>]].iloc[[<span class="number">1</span>, <span class="number">3</span>]]</span><br><span class="line">Out[<span class="number">91</span>]:</span><br><span class="line">         b     d</span><br><span class="line">beta   <span class="number">2.0</span>   <span class="number">4.0</span></span><br><span class="line">delta  <span class="number">6.0</span>  <span class="number">12.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">92</span>]: df.iloc[[<span class="number">1</span>, <span class="number">3</span>]][[<span class="string">'b'</span>, <span class="string">'d'</span>]]</span><br><span class="line">Out[<span class="number">92</span>]:</span><br><span class="line">         b     d</span><br><span class="line">beta   <span class="number">2.0</span>   <span class="number">4.0</span></span><br><span class="line">delta  <span class="number">6.0</span>  <span class="number">12.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">93</span>]: df[[<span class="string">'b'</span>, <span class="string">'d'</span>]].loc[[<span class="string">'beta'</span>, <span class="string">'delta'</span>]]</span><br><span class="line">Out[<span class="number">93</span>]:</span><br><span class="line">         b     d</span><br><span class="line">beta   <span class="number">2.0</span>   <span class="number">4.0</span></span><br><span class="line">delta  <span class="number">6.0</span>  <span class="number">12.0</span></span><br></pre></td></tr></table></figure>
<p>如果不是需要访问特定行列，而只是某个特殊位置的元素的话，dataframe.at和dataframe.iat是最快的方式，它们分别用于使用索引和下标进行访问：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">94</span>]: df.iat[<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">Out[<span class="number">94</span>]: <span class="number">8.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">95</span>]: df.at[<span class="string">'gamma'</span>, <span class="string">'d'</span>]</span><br><span class="line">Out[<span class="number">95</span>]: <span class="number">8.0</span></span><br></pre></td></tr></table></figure>
<p>dataframe.ix可以混合使用索引和下标进行访问，唯一需要注意的地方是行列内部需要一致，不可以同时使用索引和标签访问行或者列，不然的话，将会得到意外的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">97</span>]: df.ix[[<span class="number">1</span>, <span class="number">2</span>], [<span class="string">'b'</span>, <span class="string">'e'</span>]]</span><br><span class="line">Out[<span class="number">97</span>]:</span><br><span class="line">         b     e</span><br><span class="line">beta   <span class="number">2.0</span>   <span class="number">5.0</span></span><br><span class="line">gamma  <span class="number">4.0</span>  <span class="number">10.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">98</span>]: df.ix[[<span class="number">1</span>, <span class="number">2</span>], [<span class="string">'b'</span>, <span class="number">4</span>]]</span><br><span class="line">Out[<span class="number">98</span>]:</span><br><span class="line">         b   <span class="number">4</span></span><br><span class="line">beta   <span class="number">2.0</span> NaN</span><br><span class="line">gamma  <span class="number">4.0</span> NaN</span><br></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Pandas进阶]]></title>
      <url>/ml/mllib/Pandas2.html</url>
      <content type="html"><![CDATA[<p>在上一篇中我们介绍了如何创建并访问pandas的Series和DataFrame型的数据，本篇将介绍如何对pandas数据进行操作，掌握这些操作之后，基本可以处理大多数的数据了。首先，导入本篇中使用到的模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series, DataFrame</span><br></pre></td></tr></table></figure>
<p>为了看数据方便一些，我们设置一下输出屏幕的宽度<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.set_option(<span class="string">'display.width'</span>, <span class="number">200</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="数据创建的其他方式"><a href="#数据创建的其他方式" class="headerlink" title="数据创建的其他方式"></a>数据创建的其他方式</h2><p>数据结构的创建不止是上篇中介绍的标准形式，本篇再介绍几种。例如，我们可以创建一个以日期为元素的Series：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">3</span>]: dates = pd.date_range(<span class="string">'20150101'</span>, periods=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: dates</span><br><span class="line">Out[<span class="number">4</span>]: DatetimeIndex([<span class="string">'2015-01-01'</span>, <span class="string">'2015-01-02'</span>, <span class="string">'2015-01-03'</span>, <span class="string">'2015-01-04'</span>, <span class="string">'2015-01-05'</span>], dtype=<span class="string">'datetime64[ns]'</span>, freq=<span class="string">'D'</span>)</span><br></pre></td></tr></table></figure>
<p>将这个日期Series作为索引赋给一个DataFrame：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">6</span>]: df = pd.DataFrame(np.random.randn(<span class="number">5</span>, <span class="number">4</span>),index=dates,columns=list(<span class="string">'ABCD'</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: df</span><br><span class="line">Out[<span class="number">7</span>]:</span><br><span class="line">                   A         B         C         D</span><br><span class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-01</span> <span class="number">-1.920304</span>  <span class="number">1.384082</span> <span class="number">-1.371671</span> <span class="number">-0.148773</span></span><br><span class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-02</span>  <span class="number">0.250032</span> <span class="number">-0.086736</span>  <span class="number">1.213414</span> <span class="number">-0.882525</span></span><br><span class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-03</span> <span class="number">-0.711571</span> <span class="number">-0.518825</span>  <span class="number">0.517639</span>  <span class="number">0.671488</span></span><br><span class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-04</span> <span class="number">-0.065331</span> <span class="number">-1.303340</span> <span class="number">-0.234200</span>  <span class="number">1.110965</span></span><br><span class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-05</span> <span class="number">-1.258520</span> <span class="number">-0.547136</span> <span class="number">-0.292265</span> <span class="number">-0.842314</span></span><br></pre></td></tr></table></figure>
<p>只要是能转换成Series的对象，都可以用于创建DataFrame：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: df2 = pd.DataFrame(&#123; <span class="string">'A'</span> : <span class="number">1.</span>, <span class="string">'B'</span>: pd.Timestamp(<span class="string">'20150214'</span>), <span class="string">'C'</span>: pd.Series(<span class="number">1.6</span>,index=list(range(<span class="number">4</span>)),dtype=<span class="string">'float64'</span>), <span class="string">'D'</span> : np.array([<span class="number">4</span>] * <span class="number">4</span>, dtype=<span class="string">'int64'</span>), <span class="string">'E'</span> : <span class="string">'hello pandas!'</span> &#125;)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: df2</span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">     A          B    C  D              E</span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span> <span class="number">2015</span><span class="number">-02</span><span class="number">-14</span>  <span class="number">1.6</span>  <span class="number">4</span>  hello pandas!</span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span> <span class="number">2015</span><span class="number">-02</span><span class="number">-14</span>  <span class="number">1.6</span>  <span class="number">4</span>  hello pandas!</span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span> <span class="number">2015</span><span class="number">-02</span><span class="number">-14</span>  <span class="number">1.6</span>  <span class="number">4</span>  hello pandas!</span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span> <span class="number">2015</span><span class="number">-02</span><span class="number">-14</span>  <span class="number">1.6</span>  <span class="number">4</span>  hello pandas!</span><br></pre></td></tr></table></figure>
<h2 id="Pandas-处理丢失数据"><a href="#Pandas-处理丢失数据" class="headerlink" title="Pandas 处理丢失数据"></a>Pandas 处理丢失数据</h2><p>有时候我们导入或处理数据, 会产生一些空的或者是 NaN 数据,如何删除或者是填补这些 NaN 数据就是我们今天所要提到的内容.</p>
<p>建立了一个6X4的矩阵数据并且把两个位置置为空.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">13</span>]: dates = pd.date_range(<span class="string">'20130101'</span>, periods=<span class="number">6</span>)</span><br><span class="line">    ...: df = pd.DataFrame(np.arange(<span class="number">24</span>).reshape((<span class="number">6</span>,<span class="number">4</span>)),index=dates, columns=[<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>])</span><br><span class="line">    ...: df.iloc[<span class="number">0</span>,<span class="number">1</span>] = np.nan</span><br><span class="line">    ...: df.iloc[<span class="number">1</span>,<span class="number">2</span>] = np.nan</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: df</span><br><span class="line">Out[<span class="number">14</span>]:</span><br><span class="line">             A     B     C   D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">0</span>   NaN   <span class="number">2.0</span>   <span class="number">3</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>   <span class="number">4</span>   <span class="number">5.0</span>   NaN   <span class="number">7</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>   <span class="number">8</span>   <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">12</span>  <span class="number">13.0</span>  <span class="number">14.0</span>  <span class="number">15</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">16</span>  <span class="number">17.0</span>  <span class="number">18.0</span>  <span class="number">19</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">20</span>  <span class="number">21.0</span>  <span class="number">22.0</span>  <span class="number">23</span></span><br></pre></td></tr></table></figure>
<p>pd.dropna()</p>
<p>如果想直接去掉有 NaN 的行或列, 可以使用 dropna</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: df.dropna(</span><br><span class="line">    ...:     axis=<span class="number">0</span>,     <span class="comment"># 0: 对行进行操作; 1: 对列进行操作</span></span><br><span class="line">    ...:     how=<span class="string">'any'</span>   <span class="comment"># 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop</span></span><br><span class="line">    ...:     )</span><br><span class="line">    ...:</span><br><span class="line">Out[<span class="number">15</span>]:</span><br><span class="line">             A     B     C   D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>   <span class="number">8</span>   <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">12</span>  <span class="number">13.0</span>  <span class="number">14.0</span>  <span class="number">15</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">16</span>  <span class="number">17.0</span>  <span class="number">18.0</span>  <span class="number">19</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">20</span>  <span class="number">21.0</span>  <span class="number">22.0</span>  <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>pd.fillna()</p>
<p>如果是将 NaN 的值用其他值代替, 比如代替成 0:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: df.fillna(value=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">16</span>]:</span><br><span class="line">             A     B     C   D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>   <span class="number">0</span>   <span class="number">0.0</span>   <span class="number">2.0</span>   <span class="number">3</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>   <span class="number">4</span>   <span class="number">5.0</span>   <span class="number">0.0</span>   <span class="number">7</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>   <span class="number">8</span>   <span class="number">9.0</span>  <span class="number">10.0</span>  <span class="number">11</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="number">12</span>  <span class="number">13.0</span>  <span class="number">14.0</span>  <span class="number">15</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">16</span>  <span class="number">17.0</span>  <span class="number">18.0</span>  <span class="number">19</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">20</span>  <span class="number">21.0</span>  <span class="number">22.0</span>  <span class="number">23</span></span><br></pre></td></tr></table></figure>
<p>pd.isnull()</p>
<p>判断是否有缺失数据 NaN, 为 True 表示缺失数据:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">17</span>]: df.isnull()</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">                A      B      C      D</span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-01</span>  <span class="keyword">False</span>   <span class="keyword">True</span>  <span class="keyword">False</span>  <span class="keyword">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-02</span>  <span class="keyword">False</span>  <span class="keyword">False</span>   <span class="keyword">True</span>  <span class="keyword">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-03</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-04</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-05</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span></span><br><span class="line"><span class="number">2013</span><span class="number">-01</span><span class="number">-06</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span>  <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p>检测在数据中是否存在 NaN, 如果存在就返回 True:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">18</span>]: np.any(df.isnull()) == <span class="keyword">True</span></span><br><span class="line">Out[<span class="number">18</span>]: <span class="keyword">True</span></span><br></pre></td></tr></table></figure>
<h2 id="Pandas-导入导出"><a href="#Pandas-导入导出" class="headerlink" title="Pandas 导入导出"></a>Pandas 导入导出</h2><p>pandas可以读取与存取的资料格式有很多种，像csv、excel、json、html与pickle等…， 详细请看<a href="http://pandas.pydata.org/pandas-docs/stable/io.html" target="_blank" rel="noopener">官方说明文件</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#读取csv</span></span><br><span class="line">data = pd.read_csv(<span class="string">'students.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印出data</span></span><br><span class="line">print(data)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将资料存取成pickle</span></span><br><span class="line">data.to_pickle(<span class="string">'student.pickle'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Pandas-合并-concat"><a href="#Pandas-合并-concat" class="headerlink" title="Pandas 合并 concat"></a>Pandas 合并 concat</h2><p>pandas处理多组数据的时候往往会要用到数据的合并处理,使用 concat是一种基本的合并方式.而且concat中有很多参数可以调整,合并成你想要的数据形式.</p>
<h3 id="axis-合并方向"><a href="#axis-合并方向" class="headerlink" title="axis (合并方向)"></a>axis (合并方向)</h3><p>axis=0是预设值，因此未设定任何参数时，函数默认axis=0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">21</span>]: <span class="comment">#定义资料集</span></span><br><span class="line">    ...: df1 = pd.DataFrame(np.ones((<span class="number">3</span>,<span class="number">4</span>))*<span class="number">0</span>, columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">    ...: df2 = pd.DataFrame(np.ones((<span class="number">3</span>,<span class="number">4</span>))*<span class="number">1</span>, columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">    ...: df3 = pd.DataFrame(np.ones((<span class="number">3</span>,<span class="number">4</span>))*<span class="number">2</span>, columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>])</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">22</span>]: <span class="comment">#concat纵向合并</span></span><br><span class="line">    ...: res = pd.concat([df1, df2, df3], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: res</span><br><span class="line">Out[<span class="number">23</span>]:</span><br><span class="line">     a    b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br></pre></td></tr></table></figure>
<p>仔细观察会发现结果的index是0, 1, 2, 0, 1, 2, 0, 1, 2，若要将index重置，请看下面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">24</span>]: res = pd.concat([df1, df2, df3], axis=<span class="number">0</span>, ignore_index=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">25</span>]: res</span><br><span class="line">Out[<span class="number">25</span>]:</span><br><span class="line">     a    b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">6</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">7</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br><span class="line"><span class="number">8</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span>  <span class="number">2.0</span></span><br></pre></td></tr></table></figure>
<h3 id="join-合并方式"><a href="#join-合并方式" class="headerlink" title="join (合并方式)"></a>join (合并方式)</h3><p>join=’outer’为预设值，因此未设定任何参数时，函数默认join=’outer’。此方式是依照column来做纵向合并，有相同的column上下合并在一起，其他独自的column个自成列，原本没有值的位置皆以NaN填充。</p>
<p>纵向”外”合并df1与df2</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: df1 = pd.DataFrame(np.ones((<span class="number">3</span>,<span class="number">4</span>))*<span class="number">0</span>, columns=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>], index=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">    ...: df2 = pd.DataFrame(np.ones((<span class="number">3</span>,<span class="number">4</span>))*<span class="number">1</span>, columns=[<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>], index=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]:</span><br><span class="line">    ...: res = pd.concat([df1, df2], axis=<span class="number">0</span>, join=<span class="string">'outer'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">29</span>]: res</span><br><span class="line">Out[<span class="number">29</span>]:</span><br><span class="line">     a    b    c    d    e</span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  NaN</span><br><span class="line"><span class="number">3</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  NaN</span><br><span class="line"><span class="number">2</span>  NaN  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>  NaN  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  NaN  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<p>纵向”内”合并df1与df2</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: res = pd.concat([df1, df2], axis=<span class="number">0</span>, join=<span class="string">'inner'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: res</span><br><span class="line">Out[<span class="number">33</span>]:</span><br><span class="line">     b    c    d</span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<p>重置index</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">34</span>]: res = pd.concat([df1, df2], axis=<span class="number">0</span>, join=<span class="string">'inner'</span>, ignore_index=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: res</span><br><span class="line">Out[<span class="number">35</span>]:</span><br><span class="line">     b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<h3 id="join-axes-依照-axis-合并"><a href="#join-axes-依照-axis-合并" class="headerlink" title="join_axes (依照 axis 合并)"></a>join_axes (依照 axis 合并)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#依照`df1.index`进行横向合并</span></span><br><span class="line">In [<span class="number">36</span>]: res = pd.concat([df1, df2], axis=<span class="number">1</span>, join_axes=[df1.index])</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: res</span><br><span class="line">Out[<span class="number">37</span>]:</span><br><span class="line">     a    b    c    d    b    c    d    e</span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: res = pd.concat([df1, df2], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#移除join_axes，并打印结果</span></span><br><span class="line">In [<span class="number">39</span>]: res</span><br><span class="line">Out[<span class="number">39</span>]:</span><br><span class="line">     a    b    c    d    b    c    d    e</span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  NaN  NaN  NaN  NaN  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<h3 id="append-添加数据"><a href="#append-添加数据" class="headerlink" title="append (添加数据)"></a>append (添加数据)</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">41</span>]: <span class="comment">#将df2合并到df1的下面，以及重置index，并打印出结果</span></span><br><span class="line">    ...: res = df1.append(df2, ignore_index=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">42</span>]: res</span><br><span class="line">Out[<span class="number">42</span>]:</span><br><span class="line">     a    b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: <span class="comment">#合并多个df，将df2与df3合并至df1的下面，以及重置index，并打印出结果</span></span><br><span class="line">    ...: res = df1.append([df2, df3], ignore_index=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: res</span><br><span class="line">Out[<span class="number">44</span>]:</span><br><span class="line">     a    b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">4</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">5</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">6</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">7</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"><span class="number">8</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span>  <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">45</span>]: <span class="comment">#合并series，将s1合并至df1，以及重置index，并打印出结果</span></span><br><span class="line">    ...: res = df1.append(s1, ignore_index=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">46</span>]: res</span><br><span class="line">Out[<span class="number">46</span>]:</span><br><span class="line">     a    b    c    d</span><br><span class="line"><span class="number">0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></span><br><span class="line"><span class="number">3</span>  <span class="number">1.0</span>  <span class="number">2.0</span>  <span class="number">3.0</span>  <span class="number">4.0</span></span><br></pre></td></tr></table></figure>
<h2 id="Pandas-plot-出图"><a href="#Pandas-plot-出图" class="headerlink" title="Pandas plot 出图"></a>Pandas plot 出图</h2><p>这次我们讲如何将数据可视化. 首先import我们需要用到的模块，除了 pandas，我们也需要使用 numpy 生成一些数据，这节里使用的 matplotlib 仅仅是用来 show 图片的, 即 plt.show()。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p>今天我们主要是学习如何 plot data</p>
<h3 id="创建一个Series"><a href="#创建一个Series" class="headerlink" title="创建一个Series"></a>创建一个Series</h3><p>这是一个线性的数据，我们随机生成1000个数据，Series 默认的 index 就是从0开始的整数，但是这里我显式赋值以便让大家看的更清楚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">48</span>]: data = pd.Series(np.random.randn(<span class="number">1000</span>),index=np.arange(<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: data.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">50</span>]: data.plot()</span><br><span class="line">Out[<span class="number">50</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x15fc2c50</span>&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: plt.show()</span><br></pre></td></tr></table></figure>
<p>就这么简单，熟悉 matplotlib 的朋友知道如果需要plot一个数据，我们可以使用 plt.plot(x=, y=)，把x,y的数据作为参数存进去，但是data本来就是一个数据，所以我们可以直接plot。 生成的结果就是下图：<br><img src="images/685666ff.png" alt=""></p>
<h3 id="Dataframe-可视化"><a href="#Dataframe-可视化" class="headerlink" title="Dataframe 可视化"></a>Dataframe 可视化</h3><p>我们生成一个1000*4 的DataFrame，并对他们累加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">57</span>]: data = pd.DataFrame(np.random.randn(<span class="number">1000</span>,<span class="number">4</span>),index=np.arange(<span class="number">1000</span>),columns=list(<span class="string">"ABCD"</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">58</span>]: data.cumsum()</span><br><span class="line">Out[<span class="number">58</span>]:</span><br><span class="line">             A          B          C          D</span><br><span class="line"><span class="number">0</span>    <span class="number">-1.149141</span>   <span class="number">0.412332</span>  <span class="number">-2.498230</span>   <span class="number">0.879882</span></span><br><span class="line"><span class="number">1</span>    <span class="number">-1.476303</span>   <span class="number">1.130480</span>  <span class="number">-1.562601</span>   <span class="number">1.252053</span></span><br><span class="line">.....</span><br><span class="line"><span class="number">998</span>  <span class="number">22.211598</span> <span class="number">-38.707320</span> <span class="number">-18.093645</span>  <span class="number">71.655468</span></span><br><span class="line"><span class="number">999</span>  <span class="number">21.762579</span> <span class="number">-37.009749</span> <span class="number">-18.899686</span>  <span class="number">71.275606</span></span><br><span class="line"></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">4</span> columns]</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: data.plot()</span><br><span class="line">Out[<span class="number">59</span>]: &lt;matplotlib.axes._subplots.AxesSubplot at <span class="number">0x199e0e10</span>&gt;</span><br><span class="line">In [<span class="number">60</span>]: plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/2c304f5f.png" alt=""></p>
<p>这个就是我们刚刚生成的4个column的数据，因为有4组数据，所以4组数据会分别plot出来。plot 可以指定很多参数，具体的用法大家可以自己查一下这里</p>
<p>除了plot，我经常会用到还有scatter，这个会显示散点图，首先给大家说一下在 pandas 中有多少种方法:</p>
<ul>
<li>bar</li>
<li>hist</li>
<li>box</li>
<li>kde</li>
<li>area</li>
<li>scatter</li>
<li>hexbin</li>
</ul>
<p>但是我们今天不会一一介绍，主要说一下 plot 和 scatter. 因为scatter只有x，y两个属性，我们我们就可以分别给x, y指定数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">63</span>]: ax = data.plot.scatter(x=<span class="string">'A'</span>,y=<span class="string">'B'</span>,color=<span class="string">'DarkBlue'</span>,label=<span class="string">'Class1'</span>)</span><br></pre></td></tr></table></figure>
<p>然后我们在可以再画一个在同一个ax上面，选择不一样的数据列，不同的 color 和 label</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">64</span>]: data.plot.scatter(x=<span class="string">'A'</span>,y=<span class="string">'C'</span>,color=<span class="string">'LightGreen'</span>,label=<span class="string">'Class2'</span>,ax=ax)</span><br><span class="line">    ...: plt.show()</span><br><span class="line">    ...:</span><br></pre></td></tr></table></figure>
<p>下面就是我plot出来的图片</p>
<p><img src="images/df34d36c.png" alt=""></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[用Seaborn实现可视化]]></title>
      <url>/ml/mllib/Seaborn.html</url>
      <content type="html"><![CDATA[<p><strong>前言</strong></p>
<p>提升你的洞察的最好方法之一是通过可视化你的数据：这样，你可以更容易地识别模式，掌握到困难的概念以及注意到关键的要素，当你使用数据科学中的Python时，你很有可能已经用了Matplotlib,一个供你创建高质量图像的2D库。另一个免费的可视化库是Seabon,他提供了一个绘制统计图形的高级接口。</p>
<p>这篇文章覆盖了大部分常见问题，当用户开始用Seaborn库的时候，下面有多少问题，你能正确地回答。</p>
<ul>
<li>1.用Seaborn VS Matplotlib ？</li>
<li>2.如何装载数据来构建Seaborn点</li>
<li>3.如何显示Seaborn点</li>
<li>4.如何在默认matplotlib的情况下，使用Seaborn</li>
<li>5.如何调整Seaborn的上下文环境</li>
<li>6.如何调整图像样式</li>
<li>7.如何旋转标签文字</li>
<li>8.如何设置X/Y坐标</li>
<li>9.如何设置刻度</li>
<li>10.如何添加标题</li>
</ul>
<p><strong>原文地址</strong>：<a href="https://www.datacamp.com/community/tutorials/seaborn-python-tutorial#sm" target="_blank" rel="noopener">https://www.datacamp.com/community/tutorials/seaborn-python-tutorial#sm</a></p>
<p>如果对Matplotlib及Seaborn感兴趣的话，请参加DataCamp的课程<a href="https://link.jianshu.com/?t=https://www.datacamp.com/courses/introduction-to-data-visualization-with-python" target="_blank" rel="noopener">Introduction to Data Visualization with Python</a>.</p>
<h2 id="Seaborn-vs-Matplotlib"><a href="#Seaborn-vs-Matplotlib" class="headerlink" title="Seaborn vs Matplotlib"></a>Seaborn vs Matplotlib</h2><p>正如你所知道的，Seaborn是比Matplotlib更高级的免费库，特别地以数据可视化为目标，但他要比这一切更进一步：他解决了用Matplotlib的2个最大问题，正如Michael Waskom所说的：Matplotlib试着让简单的事情更加简单，困难的事情变得可能，那么Seaborn就是让困难的东西更加简单。</p>
<p>用Matplotlib最大的困难是其默认的各种参数，而Seaborn则完全避免了这一问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the necessary libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize Figure and Axes object</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load in data</span></span><br><span class="line">tips =   pd.read_csv(<span class="string">"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create violinplot</span></span><br><span class="line">ax.violinplot(tips[<span class="string">"total_bill"</span>], vert=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/b5fb2a19.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the necessary libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the data</span></span><br><span class="line">tips =       pd.read_csv(<span class="string">"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create violinplot</span></span><br><span class="line">sns.violinplot(x = <span class="string">"total_bill"</span>, data=tips)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/2b4ce28f.png" alt=""></p>
<p>Matplotlib的默认风格，通常不会增加颜色以及坐标轴的刻度标签以及样式。<br>而且Seaborn是Matplotlib的延伸和扩展，如果你知道Matplotlib，你就已经掌握了Seaborn的大部分；</p>
<h2 id="如何加载数据构建Seaborn图像"><a href="#如何加载数据构建Seaborn图像" class="headerlink" title="如何加载数据构建Seaborn图像"></a>如何加载数据构建Seaborn图像</h2><p>当您使用Seaborn时，您可以使用库本身提供的内置数据集之一，也可以加载Pandas DataFrame。</p>
<h3 id="装载内置海床数据集"><a href="#装载内置海床数据集" class="headerlink" title="装载内置海床数据集"></a>装载内置海床数据集</h3><p>要开始使用内置的Seaborn数据集，可以使用load_dataset（）函数。 要查看内置的所有数据集，请点击此处查看 <a href="https://github.com/mwaskom/seaborn-data" target="_blank" rel="noopener">https://github.com/mwaskom/seaborn-data</a> 。 请查看以下示例来查看load_dataset（）函数的工作原理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import necessary libraries</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load iris data</span></span><br><span class="line">iris = sns.load_dataset(<span class="string">"iris"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct iris plot</span></span><br><span class="line">sns.swarmplot(x=<span class="string">"species"</span>, y=<span class="string">"petal_length"</span>, data=iris)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/0cd3ba89.png" alt=""></p>
<h3 id="加载您自己的DataFrame数据集"><a href="#加载您自己的DataFrame数据集" class="headerlink" title="加载您自己的DataFrame数据集"></a>加载您自己的DataFrame数据集</h3><p>当然，数据可视化的大部分场景您将使用自己的数据，而不是Seaborn库的内置数据集。 Seaborn最适用于包含整个数据集的Pandas DataFrames和数组</p>
<p>DataFrames是一种在矩形网格中存储数据的方法，DataFrame的行不需要包含相同类型的值：它们可以是数字，字符，逻辑等。特别是对于Python，DataFrames集成于Pandas库中，它们被定义为具有潜在不同类型的列的二维标记数据结构。</p>
<p>Seaborn对DataFrames非常好的原因是，因为DataFrames的标签会自动传播到绘图或其他数据结构，正如本教程的第一个示例所示，您在Seaborn中绘制了一个小提琴。在那里，你看到x轴有一个传说total_bill，而Matplotlib图则不是这样。这已经需要很多工作了。</p>
<p>但这并不意味着所有的工作都完成了 - 恰恰相反。在许多情况下，您仍然需要操作您的Pandas DataFrame，以使绘图正确呈现。如果您想了解更多信息，请查看DataCamp的Python中的DataFrames Pandas教程或Pandas Foundations课程</p>
<p>Matplotlib仍然是Seaborn的基础，这意味着结构仍然是一样的，您需要使用plt.show（）使图像显示给您。 您可能已经从本教程上一个示例中看到过。 在任何情况下，这里是另一个例子，其中show（）函数用于显示绘图</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import necessarily libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">"titanic"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up a factorplot</span></span><br><span class="line">g = sns.factorplot(<span class="string">"class"</span>, <span class="string">"survived"</span>, <span class="string">"sex"</span>, data=titanic, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>, legend=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="如何显示Seaborn点"><a href="#如何显示Seaborn点" class="headerlink" title="如何显示Seaborn点"></a>如何显示Seaborn点</h2><p>matplotlib仍然是Seaborn的基础，这意味着绘图方面两者仍然是相同的，你就需要使用plt.show()显示图像。您可能已经在本教程的前一个示例中看到了这一点。在任何情况下，下面是另一个示例, 其中show() 函数用于显示图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import necessarily libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">"titanic"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up a factorplot</span></span><br><span class="line">g = sns.factorplot(<span class="string">"class"</span>, <span class="string">"survived"</span>, <span class="string">"sex"</span>, data=titanic, kind=<span class="string">"bar"</span>, palette=<span class="string">"muted"</span>, legend=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/bba0fd1a.png" alt=""></p>
<blockquote>
<p>注意：在上面的代码块中, 您使用内置的 Seaborn 数据集, 并使用它创建一个 factorplot。factorplot 是一个多类型绘图，上面例子中是一个柱状图，因为你设置的参数为’柱状’，同时, 你还可以应设置颜色参数, 并将图例设置为 False</p>
</blockquote>
<h2 id="如何使用Seaborn用Matplotlib的默认值"><a href="#如何使用Seaborn用Matplotlib的默认值" class="headerlink" title="如何使用Seaborn用Matplotlib的默认值"></a>如何使用Seaborn用Matplotlib的默认值</h2><p>也有很多相反的场景，即那些使用Seaborn并希望用Matplotlib默认设置的问题。</p>
<p>之前，您可以通过从Seaborn包导入apionly模块来解决这个问题。 现在已经弃用了（自2017年7月起）。 导入Seaborn时，不再应用默认样式，因此您需要显式调用set（）或set_style（），set_context（）和set_palette（）中的一个或多个以获取Seaborn或Matplotlib默认的绘图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Matplotlib</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the available styles</span></span><br><span class="line">plt.style.available</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use Matplotlib defaults</span></span><br><span class="line">plt.style.use(<span class="string">"classic"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="如何在Matplotlib中使用Seaborn的颜色作为色彩？"><a href="#如何在Matplotlib中使用Seaborn的颜色作为色彩？" class="headerlink" title="如何在Matplotlib中使用Seaborn的颜色作为色彩？"></a>如何在Matplotlib中使用Seaborn的颜色作为色彩？</h2><p>如何将Seaborn颜色引入Matplotlib图中的问题。 您可以使用color_palette（）来定义要使用的颜色映射和参数n_colors的颜色数。 在这种情况下，这个例子将假设有5个标签分配给在data1和data2中定义的数据点，所以这就是为什么你传递5到这个参数，你也做一个长度等于N的列表，其中5个整数变化 在可变颜色</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the necessary libraries</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a variable N</span></span><br><span class="line">N = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct the colormap</span></span><br><span class="line">current_palette = sns.color_palette(<span class="string">"muted"</span>, n_colors=<span class="number">5</span>)</span><br><span class="line">cmap = ListedColormap(sns.color_palette(current_palette).as_hex())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize the data</span></span><br><span class="line">data1 = np.random.randn(N)</span><br><span class="line">data2 = np.random.randn(N)</span><br><span class="line"><span class="comment"># Assume that there are 5 possible labels</span></span><br><span class="line">colors = np.random.randint(<span class="number">0</span>,<span class="number">5</span>,N)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a scatter plot</span></span><br><span class="line">plt.scatter(data1, data2, c=colors, cmap=cmap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a color bar</span></span><br><span class="line">plt.colorbar()</span><br></pre></td></tr></table></figure>
<p><img src="images/50033c1e.png" alt=""></p>
<h2 id="如何在Seaborn中旋转标签文本"><a href="#如何在Seaborn中旋转标签文本" class="headerlink" title="如何在Seaborn中旋转标签文本"></a>如何在Seaborn中旋转标签文本</h2><p>要在Seaborn图中旋转标签文本，您需要处理图级别。 请注意，在下面的代码块中，您可以使用FacetGrid方法之一，即set_xticklabels来旋转文本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import the necessary libraries</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize the data</span></span><br><span class="line">x = <span class="number">10</span> ** np.arange(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line">data = pd.DataFrame(data=&#123;<span class="string">'x'</span>: x, <span class="string">'y'</span>: y&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an lmplot</span></span><br><span class="line">grid = sns.lmplot(<span class="string">'x'</span>, <span class="string">'y'</span>, data, size=<span class="number">7</span>, truncate=<span class="keyword">True</span>, scatter_kws=&#123;<span class="string">"s"</span>: <span class="number">100</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rotate the labels on x-axis</span></span><br><span class="line">grid.set_xticklabels(rotation=<span class="number">90</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the plot</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/b84436f2.png" alt=""></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Numpy入门]]></title>
      <url>/ml/mllib/index.html</url>
      <content type="html"><![CDATA[<h2 id="Numpy介绍"><a href="#Numpy介绍" class="headerlink" title="Numpy介绍"></a>Numpy介绍</h2><p>Numpy是Python的一个开源科学计算的库，提供了矩阵运算的功能，其一般与Scipy、matplotlib一起使用。</p>
<p>NumPy提供了两种基本的对象：<code>ndarray</code>（N-dimensional array object）和 <code>ufunc</code>（universal function object）。ndarray(下文统一称之为数组)是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数。</p>
<p><strong>环境说明</strong>： python3.6</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">print(np.version.version)</span><br><span class="line"><span class="number">1.13</span><span class="number">.3</span></span><br></pre></td></tr></table></figure>
<h3 id="ndarray"><a href="#ndarray" class="headerlink" title="ndarray"></a>ndarray</h3><p>ndarray是一个多维数组对象，由两部分构成：</p>
<blockquote>
<p>实际的数据</p>
<p>描述这些数据的元数据（数据维度、数据类型等）</p>
</blockquote>
<p>ndarray数组一般要求所有元素类型相同（同质），数组下标从0开始;</p>
<p>在NumPy中数组的维度(dimensions)叫做轴(axis)，轴的个数叫做秩(rank)。</p>
<h2 id="创建ndarray"><a href="#创建ndarray" class="headerlink" title="创建ndarray"></a>创建ndarray</h2><ul>
<li>从Python中的列表、元组等类型创建ndarray数组
　　</li>
</ul>
<p>可以使用np.array()方法将Python列表或元组转化为数组，转化后的数组元素的类型由原来的对象的类型来决定。</p>
<p>（1）一维数组<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.array((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))  <span class="comment">#从元组创建</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>（2）多维数组<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])   <span class="comment">#从列表创建</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],(<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)])   <span class="comment">#从列表和元组混合类型创建</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure></p>
<p>当np.array()不指定dtype时，NumPy将根据数据情况关联一个dtype类型。</p>
<ul>
<li>使用NumPy中函数创建ndarray数组，如：arange, ones, zeros等</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>np.arange(n)</td>
<td>类似range()函数，返回ndarray类型，元素从0到n‐1</td>
</tr>
<tr>
<td>np.ones(shape)</td>
<td>根据shape生成一个全1数组，shape是元组类型</td>
</tr>
<tr>
<td>np.zeros(shape)</td>
<td>根据shape生成一个全0数组，shape是元组类型</td>
</tr>
<tr>
<td>np.full(shape,val)</td>
<td>根据shape生成一个数组，每个元素值都是val</td>
</tr>
<tr>
<td>np.eye(n)</td>
<td>创建一个正方的n*n单位矩阵，对角线为1，其余为0</td>
</tr>
<tr>
<td>np.ones_like(a)</td>
<td>根据数组a的形状生成一个全1数组</td>
</tr>
<tr>
<td>np.zeros_like(a)</td>
<td>根据数组a的形状生成一个全0数组</td>
</tr>
<tr>
<td>np.full_like(a,val)</td>
<td>根据数组a的形状生成一个数组，每个元素值都是val</td>
</tr>
<tr>
<td>np.linspace()</td>
<td>根据起止数据等间距地填充数据，形成数组</td>
</tr>
<tr>
<td>np.concatenate()</td>
<td>将两个或多个数组合并成一个新的数组</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.arange(<span class="number">6</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.ones(<span class="number">6</span>)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.zeros((<span class="number">3</span>,<span class="number">2</span>))</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.full((<span class="number">2</span>,<span class="number">2</span>),<span class="number">6</span>)</span><br><span class="line">array([[<span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.eye(<span class="number">3</span>)</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.ones_like(a) <span class="comment">#生成一个与a数组相同结构的全1数组</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">6</span>)   <span class="comment"># 1为起始数，10为终止数，6为数的个数</span></span><br><span class="line">array([  <span class="number">1.</span> ,   <span class="number">2.8</span>,   <span class="number">4.6</span>,   <span class="number">6.4</span>,   <span class="number">8.2</span>,  <span class="number">10.</span> ])</span><br></pre></td></tr></table></figure>
<h2 id="ndarray的属性"><a href="#ndarray的属性" class="headerlink" title="ndarray的属性"></a>ndarray的属性</h2><p><strong>shape</strong>：一个说明ndarray对象各维度大小的元组；对一个n 行m 列的矩阵来说，shape为 (n,m)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.shape</span><br><span class="line">(<span class="number">4</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.shape = <span class="number">2</span>, <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>k = c.reshape(<span class="number">4</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>k</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>k[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>k</span><br><span class="line">array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用数组的reshape方法，可以创建一个改变了尺寸的新数组，原数组的shape保持不变。</p>
<p>k与c共享内存区域，所以修改其中任意一个数组的元素都会同时修改另外一个数组的内容。</p>
</blockquote>
<p><strong>dtype</strong>：ndarray对象的元素类型;数组的元素类型可以通过dtype属性获得，可以通过dtype参数在创建时指定元素类型。类型可以是 numpy.int32, numpy.int16, and numpy.float64 等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.dtype</span><br><span class="line">dtype(<span class="string">'int32'</span>)</span><br></pre></td></tr></table></figure>
<p>创建数组时也可以指定元素的数据类型:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]], dtype = np.float)</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">       [ <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">8.</span>]])</span><br></pre></td></tr></table></figure></p>
<p><strong>ndim</strong>：数组的维数，也称为rank(秩)<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.ndim</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p><strong>size</strong>：ndarray对象元素的个数<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.size</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure></p>
<p><strong>itemsize</strong>：ndarray对象中每个元素的大小，即占用的字节数。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.itemsize</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure></p>
<p><strong>data</strong>：指向数据内存。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.data</span><br><span class="line">&lt;read-write buffer <span class="keyword">for</span> <span class="number">0x02D89E30</span>, size <span class="number">32</span>, offset <span class="number">0</span> at <span class="number">0x02CE7DE0</span>&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="ndarray的数据类型"><a href="#ndarray的数据类型" class="headerlink" title="ndarray的数据类型"></a>ndarray的数据类型</h2><p>Python语法仅支持整数、浮点数和复数3种类型，而ndarray支持多种数据类型，这也正是其用于科学计算的强大之处。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>bool</td>
<td>布尔类型，True或False</td>
</tr>
<tr>
<td>intc</td>
<td>与C语言中的int类型一致，一般是int32或int64</td>
</tr>
<tr>
<td>intp</td>
<td>用于索引的整数，与C语言中ssize_t一致，int32或int64</td>
</tr>
<tr>
<td>int8</td>
<td>字节长度的整数，取值：[‐128, 127]</td>
</tr>
<tr>
<td>int16</td>
<td>16位长度的整数，取值：[‐32768, 32767]</td>
</tr>
<tr>
<td>int32</td>
<td>32位长度的整数，取值：[‐2^31,2^31‐1]</td>
</tr>
<tr>
<td>int64</td>
<td>64位长度的整数，取值：[‐2^63,2^63‐1]</td>
</tr>
<tr>
<td>uint8</td>
<td>8位无符号整数，取值：[0, 255]</td>
</tr>
<tr>
<td>uint16</td>
<td>16位无符号整数，取值：[0, 65535]</td>
</tr>
<tr>
<td>uint32</td>
<td>32位无符号整数，取值：[0,2^32‐1]</td>
</tr>
<tr>
<td>uint64</td>
<td>32位无符号整数，取值：[0,2^64‐1]</td>
</tr>
<tr>
<td>float16</td>
<td>16位半精度浮点数：1位符号位，5位指数，10位尾数</td>
</tr>
<tr>
<td>float32</td>
<td>32位半精度浮点数：1位符号位，8位指数，23位尾数</td>
</tr>
<tr>
<td>float64</td>
<td>64位半精度浮点数：1位符号位，11位指数，52位尾数</td>
</tr>
<tr>
<td>complex64</td>
<td>复数类型，实部和虚部都是32位浮点数</td>
</tr>
<tr>
<td>complex128</td>
<td>复数类型，实部和虚部都是64位浮点数</td>
</tr>
</tbody>
</table>
<h2 id="ndarray数组的操作"><a href="#ndarray数组的操作" class="headerlink" title="ndarray数组的操作"></a>ndarray数组的操作</h2><h3 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h3><ul>
<li><p>索引：获取数组中特定位置元素的过程</p>
</li>
<li><p>切片：获取数组元素子集的过程</p>
</li>
</ul>
<p>一维数组的索引和切片<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">2</span>]</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">-2</span>]   <span class="comment"># 从右开始</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:<span class="number">4</span>]      <span class="comment"># 起始编号:终止编号(不含):步长</span></span><br><span class="line">array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">0</span>:<span class="number">6</span>:<span class="number">2</span>]    <span class="comment"># 指定步长为2</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>多维数组的索引和切片<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">-1</span>,<span class="number">-2</span>]    <span class="comment"># 从右开始</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="comment"># 选取一个维度用:，不同维度用逗号分开</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[:<span class="number">1</span>, <span class="number">1</span>:]   <span class="comment"># 每个维度切片方法与一维数组相同</span></span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>]])</span><br></pre></td></tr></table></figure></p>
<h3 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h3><ul>
<li>一元函数</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>np.abs(x) np.fabs(x)</td>
<td>计算数组各元素的绝对值</td>
</tr>
<tr>
<td>np.sqrt(x)</td>
<td>计算数组各元素的平方根</td>
</tr>
<tr>
<td>np.square(x)</td>
<td>计算数组各元素的平方</td>
</tr>
<tr>
<td>np.log(x) np.log10(x) np.log2(x)</td>
<td>计算数组各元素的自然对数、10底对数和2底对数</td>
</tr>
<tr>
<td>np.ceil(x) np.floor(x)</td>
<td>计算数组各元素的ceiling值 或 floor值</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">-2</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.abs(a)</span><br><span class="line">array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">-2</span>,  <span class="number">4</span>,  <span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.fabs(a)</span><br><span class="line">array([ <span class="number">2.</span>,  <span class="number">4.</span>,  <span class="number">6.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.square(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([ <span class="number">4</span>, <span class="number">16</span>, <span class="number">36</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.sqrt(b)</span><br><span class="line">array([ <span class="number">2.</span>,  <span class="number">4.</span>,  <span class="number">6.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.log2(b)</span><br><span class="line">array([ <span class="number">2.</span>      ,  <span class="number">4.</span>      ,  <span class="number">5.169925</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([<span class="number">0.2</span>, <span class="number">1.5</span>, <span class="number">2.8</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.ceil(a)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.floor(a)</span><br><span class="line">array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>np.rint(x)</td>
<td>计算数组各元素的四舍五入值</td>
</tr>
<tr>
<td>np.modf(x)</td>
<td>将数组各元素的小数和整数部分以两个独立数组形式返回</td>
</tr>
<tr>
<td>np.cos(x) np.cosh(x)</td>
<td>计算数组各元素的普通型和双曲型三角函数</td>
</tr>
<tr>
<td>np.sin(x) np.sinh(x)</td>
<td>计算数组各元素的普通型和双曲型三角函数</td>
</tr>
<tr>
<td>np.tan(x) np.tanh(x)</td>
<td>计算数组各元素的普通型和双曲型三角函数</td>
</tr>
<tr>
<td>np.exp(x)</td>
<td>计算数组各元素的指数值</td>
</tr>
<tr>
<td>np.sign(x)</td>
<td>计算数组各元素的符号值，1(+),0,‐1(‐)</td>
</tr>
</tbody>
</table>
<ul>
<li>二元函数</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>+, ‐, , /, *</td>
<td>两个数组各元素进行对应运算</td>
</tr>
<tr>
<td>np.maximum(x,y) np.fmax()</td>
<td>元素级的最大值/最小值计算</td>
</tr>
<tr>
<td>np.minimum(x,y) np.fmin()</td>
<td>元素级的最大值/最小值计算</td>
</tr>
<tr>
<td>np.mod(x,y)</td>
<td>元素级的模运算</td>
</tr>
<tr>
<td>np.copysign(x,y)</td>
<td>将数组y中各元素值的符号赋值给数组x对应元素</td>
</tr>
<tr>
<td>>, &lt;, &gt;=, &lt;=, ==, !=</td>
<td>算术比较，产生布尔型数组</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a + b</span><br><span class="line">array([[ <span class="number">2</span>,  <span class="number">4</span>,  <span class="number">6</span>],</span><br><span class="line">       [ <span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a - b</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a * b</span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a / b</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a**<span class="number">2</span></span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">9</span>],</span><br><span class="line">       [<span class="number">16</span>, <span class="number">25</span>, <span class="number">36</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.maximum(a, b)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.fmax(a, b)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.mod(a, b)</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a &gt;= b</span><br><span class="line">array([[ <span class="keyword">True</span>,  <span class="keyword">True</span>,  <span class="keyword">True</span>],</span><br><span class="line">       [ <span class="keyword">True</span>,  <span class="keyword">True</span>,  <span class="keyword">True</span>]], dtype=bool)</span><br></pre></td></tr></table></figure>
<h2 id="ndarray数组的变换"><a href="#ndarray数组的变换" class="headerlink" title="ndarray数组的变换"></a>ndarray数组的变换</h2><h3 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h3><table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>.reshape(shape)</td>
<td>不改变数组元素，返回一个shape形状的数组，原数组不变</td>
</tr>
<tr>
<td>.resize(shape)</td>
<td>与.reshape()功能一致，但修改原数组</td>
</tr>
<tr>
<td>.swapaxes(ax1,ax2)</td>
<td>将数组n个维度中两个维度进行调换</td>
</tr>
<tr>
<td>.flatten()</td>
<td>对数组进行降维，返回折叠后的一维数组，原数组不变</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.ones((<span class="number">2</span>,<span class="number">6</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.resize((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.flatten()</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="类型变换"><a href="#类型变换" class="headerlink" title="类型变换"></a>类型变换</h3><p>astype()方法一定会创建新的数组（原始数据的一个拷贝），即使两个类型一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.ones((<span class="number">2</span>,<span class="number">3</span>), dtype=np.int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.astype(np.float)</span><br><span class="line">array([[ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">1.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="转换成列表"><a href="#转换成列表" class="headerlink" title="转换成列表"></a>转换成列表</h3><p>tolist()方式可以实现将ndarray数组转换成列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.ones((<span class="number">2</span>,<span class="number">3</span>), dtype=np.int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.tolist()</span><br><span class="line">[[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[深入探索MNIST]]></title>
      <url>/ml/tensorflow/deep-mnist.html</url>
      <content type="html"><![CDATA[<p>TensorFlow是一个非常强大的用来做大规模数值计算的库。其所擅长的任务之一就是实现以及训练深度神经网络。</p>
<p>在本教程中，我们将学到构建一个TensorFlow模型的基本步骤，并将通过这些步骤为MNIST构建一个深度卷积神经网络。</p>
<p>本介绍假定熟悉神经网络和 MNIST 数据集。如果你没有他们的背景, 看看<a href="/ml/tensorflow/">新手指南</a>。请务必在启动前安装 TensorFlow。</p>
<h2 id="关于本教程"><a href="#关于本教程" class="headerlink" title="关于本教程"></a>关于本教程</h2><p>本教程的第一部分解释了 <a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py" target="_blank" rel="noopener">mnist_softmax.py</a>, 这是 Tensorflow 模型的基本实现。第二部分介绍了提高测量精度的方法。</p>
<p>您可以将本教程中的每个代码段复制并粘贴到 Python 环境中, 或者您可以从 <a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_deep.py" target="_blank" rel="noopener">mnist_deep.py</a> 下载完全实现的代码。</p>
<p>我们将在本教程中完成的任务：</p>
<ul>
<li>创建一个softmax回归函数，该函数是基于查看图像中的每个像素来识别mnist数据的模型</li>
<li>使用 Tensorflow 来训练模型, 通过让它 “看” 成千上万的例子来识别数字 (并运行我们的第一个 Tensorflow 会话</li>
<li>用我们的测试数据检查模型的准确性</li>
<li>构建、训练和测试多层卷积神经网络以提高结果</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在创建模型之前，我们会先加载MNIST数据集，然后启动一个TensorFlow的session。</p>
<h3 id="加载MNIST数据"><a href="#加载MNIST数据" class="headerlink" title="加载MNIST数据"></a>加载MNIST数据</h3><p>为了方便起见，我们已经准备了<a href="https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py" target="_blank" rel="noopener">一个脚本</a>来自动下载和导入MNIST数据集。它会自动创建一个 <code>&#39;MNIST_data&#39;</code> 的目录来存储数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>这里，<code>mnist</code> 是一个轻量级的类。它以Numpy数组的形式存储着训练、校验和测试数据集。同时提供了一个函数，用于在迭代中获得 <code>minibatch</code> ，后面我们将会用到。</p>
<h3 id="运行InteractiveSession"><a href="#运行InteractiveSession" class="headerlink" title="运行InteractiveSession"></a>运行InteractiveSession</h3><p>Tensorflow依赖于一个高效的C++后端来进行计算。与后端的这个连接叫做session。一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。</p>
<p>这里，我们使用更加方便的 <code>InteractiveSession</code> 类。通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些<a href="https://www.tensorflow.org/versions/master/get_started/get_started#the_computational_graph" target="_blank" rel="noopener">计算图</a>，这些计算图是由某些操作(operations)构成的。这对于工作在交互式环境中的人们来说非常便利，比如使用IPython。如果你没有使用 <code>InteractiveSession</code>，那么你需要在启动session之前构建整个计算图，然后<a href="https://www.tensorflow.org/versions/master/get_started/get_started#the_computational_graph" target="_blank" rel="noopener">启动该计算图</a>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>为了在 python 中进行高效的数值计算, 我们通常使用像 NumPy 这样的库, 它使用其他语言实现的高效代码, 例如在 python 之外执行昂贵的运算 (如矩阵乘法)。不幸的是, 在每个操作中切换回 Python 仍然会有很多开销。如果要在 gpu 或分布式方式下运行计算, 而传输数据的成本很高, 这一开销更加可怖。</p>
<p>TensorFlow也是在Python外部完成其主要工作，但是进行了改进以避免这种开销。其并没有采用在Python外部独立运行某个耗时操作的方式，而是先让我们描述一个交互操作图，然后完全将其运行在Python外部。这与Theano或Torch的做法类似。</p>
<p>因此Python代码的目的是用来构建这个可以在外部运行的计算图，以及安排计算图的哪一部分应该被运行。详情请查看<a href="/ml/tensorflow/">tensroflow入门</a>中的计算图表一节。</p>
<h2 id="构建Softmax-回归模型"><a href="#构建Softmax-回归模型" class="headerlink" title="构建Softmax 回归模型"></a>构建Softmax 回归模型</h2><p>在这一节中我们将建立一个拥有一个线性层的softmax回归模型。在下一节，我们会将其扩展为一个拥有多层卷积网络的softmax回归模型。</p>
<h3 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h3><p>我们通过为输入图像和目标输出类别创建节点，来开始构建计算图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>这里的<code>x</code>和<code>y</code>并不是特定的值，相反，他们都只是一个<code>占位符</code>，可以在TensorFlow运行某一计算时根据该占位符输入具体的值。</p>
<p>输入图片x是一个2维的浮点数张量。这里，分配给它的<code>shape</code>为<code>[None, 784]</code>，其中<code>784</code>是一张展平的MNIST图片的维度。<code>None</code>表示其值大小不定，在这里作为第一个维度值，用以指代batch的大小，意即<code>x</code>的数量不定。输出类别值<code>y_</code>也是一个2维张量，其中每一行为一个10维的one-hot向量,用于代表对应某一MNIST图片的类别。</p>
<p>虽然<code>placeholder</code>的<code>shape</code>参数是可选的，但有了它，TensorFlow能够自动捕捉因数据维度不一致导致的错误。</p>
<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>我们现在为模型定义权重W和偏置b。可以将它们当作额外的输入量，但是TensorFlow有一个更好的处理方式：变量。一个变量代表着TensorFlow计算图中的一个值，能够在计算过程中使用，甚至进行修改。在机器学习的应用过程中，模型参数一般用Variable来表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<p>我们在调用<code>tf.Variable</code>的时候传入初始值。在这个例子里，我们把<code>W</code>和<code>b</code>都初始化为零向量。<code>W</code>是一个784x10的矩阵（因为我们有784个特征和10个输出值）。b是一个10维的向量（因为我们有10个分类）。</p>
<p><code>变量</code>需要通过seesion初始化后，才能在session中使用。这一初始化步骤为，为初始值指定具体值（本例当中是全为零），并将其分配给每个<code>变量</code>,可以一次性为所有<code>变量</code>完成此操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure>
<h3 id="类别预测与损失函数"><a href="#类别预测与损失函数" class="headerlink" title="类别预测与损失函数"></a>类别预测与损失函数</h3><p>现在我们可以实现我们的回归模型了。这只需要一行！我们把向量化后的图片x和权重矩阵W相乘，加上偏置b，然后计算每个分类的softmax概率值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = tf.matmul(x,W) + b</span><br></pre></td></tr></table></figure>
<p>我们可以简单地指定一个损失函数。损失表明模型的预测在一个单一的例子是多么糟糕;我们试图尽量减少, 而在所有的例子培训。在这里, 我们的损失函数是熵的目标和 softmax 激活函数应用于模型的预测。在初学者教程中, 我们使用稳定的公式:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(</span><br><span class="line">    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))</span><br></pre></td></tr></table></figure>
<p>请注意, <code>tf.nn.softmax_cross_entropy_with_logits</code> 内部将 softmax 应用于模型的规范化模型预测和所有类的求和, 而 <code>tf. reduce_mean</code> 的平均值超过这些总和。</p>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>我们已经定义好模型和训练用的损失函数，那么用TensorFlow进行训练就很简单了。因为TensorFlow知道整个计算图，它可以使用自动微分法找到对于各个变量的损失的梯度值。TensorFlow有<a href="https://www.tensorflow.org/versions/master/api_guides/python/train#optimizers" target="_blank" rel="noopener">大量内置的优化算法</a> 这个例子中，我们用最速下降法让交叉熵下降，步长为0.5.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<p>这一行代码实际上是用来往计算图上添加一个新操作，其中包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。</p>
<p>返回的<code>train_step</code>操作对象，在运行时会使用梯度下降来更新参数。因此，整个模型的训练可以通过反复地运行<code>train_step</code>来完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  batch = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">  train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>]&#125;)</span><br></pre></td></tr></table></figure>
<p>每一步迭代，我们都会加载100个训练样本，然后执行一次<code>train_step</code>，并通过<code>feed_dict</code>将<code>x</code> 和 <code>y_</code>张量<code>占位符</code>用训练训练数据替代。</p>
<p>注意，在计算图中，你可以用<code>feed_dict</code>来替代任何张量，并不仅限于替换占位符。</p>
<h3 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h3><p>那么我们的模型性能如何呢？</p>
<p>首先让我们找出那些预测正确的标签。<code>tf.argmax</code> 是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如<code>tf.argmax(y,1)</code>返回的是模型对于任一输入x预测到的标签值，而 <code>tf.argmax(y_,1)</code> 代表正确的标签，我们可以用 <code>tf.equal</code> 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这里返回一个布尔数组。为了计算我们分类的准确率，我们将布尔值转换为浮点数来代表对、错，然后取平均值。例如：<code>[True, False, True, True]</code>变为<code>[1,0,1,1]</code>，计算出平均值为0.75。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br></pre></td></tr></table></figure>
<p>最后，我们可以计算出在测试数据上的准确率，大概是92%。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<h2 id="构建一个多层卷积网络"><a href="#构建一个多层卷积网络" class="headerlink" title="构建一个多层卷积网络"></a>构建一个多层卷积网络</h2><p>在MNIST上只有92%正确率，实在太糟糕。在这个小节里，我们用一个稍微复杂的模型：卷积神经网络来改善效果。这会达到大概99.2%的准确率。虽然不是最高，但是还是比较让人满意。</p>
<p>这里是一个用张量板创建的关于我们将建立的模型的图表:</p>
<p><img src="images/6093ed9c.png" alt=""></p>
<h3 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h3><p>为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">  <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">  <span class="keyword">return</span> tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<h3 id="卷积和池化"><a href="#卷积和池化" class="headerlink" title="卷积和池化"></a>卷积和池化</h3><p>TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="第一层卷积"><a href="#第一层卷积" class="headerlink" title="第一层卷积"></a>第一层卷积</h3><p>现在我们可以开始实现第一层了。它由一个卷积接一个max pooling完成。卷积在每个5x5的patch中算出32个特征。卷积的权重张量形状是<code>[5, 5, 1, 32]</code>，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>])</span><br></pre></td></tr></table></figure>
<p>为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>我们把<code>x_image</code>和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pool。<code>max_pool_2x2</code> 方法将图像大小缩小为14x14。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br></pre></td></tr></table></figure>
<h3 id="第二层卷积"><a href="#第二层卷积" class="headerlink" title="第二层卷积"></a>第二层卷积</h3><p>为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br></pre></td></tr></table></figure>
<h3 id="密集连接层"><a href="#密集连接层" class="headerlink" title="密集连接层"></a>密集连接层</h3><p>现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line"></span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br></pre></td></tr></table></figure>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>为了减少过拟合，我们在输出层之前加入dropout。我们用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br></pre></td></tr></table></figure>
<h3 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h3><p>最后，我们添加一个softmax层，就像前面的单层softmax regression一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</span><br></pre></td></tr></table></figure>
<h3 id="训练和评估模型"><a href="#训练和评估模型" class="headerlink" title="训练和评估模型"></a>训练和评估模型</h3><p>这个模型的效果如何呢？为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码。</p>
<p>不同的是：</p>
<ul>
<li>我们将取代最陡峭的梯度下降优化器与更复杂的 ADAM优化器。</li>
<li>在feed_dict中加入额外的参数keep_prob来控制dropout比例</li>
<li>每100次迭代输出一次日志。</li>
</ul>
<p>我们也将使用 <code>tf.Session</code> 而不是 <code>tf.InteractiveSession</code>, 这更好地区分了创建图形 (模型规范) 的过程和计算图 (模型拟合) 的过程。它通常会使代码更简洁。<code>tf.Session</code> 在 <a href="https://docs.python.org/3/whatsnew/2.6.html#pep-343-the-with-statement" target="_blank" rel="noopener">with block</a> 中创建, 以便在块退出后自动销毁。</p>
<p>随时运行此代码。请注意, 它会进行2万次训练迭代, 并且可能需要一段时间 (可能长达半小时), 这取决于您的处理器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))</span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  sess.run(tf.global_variables_initializer())</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">      train_accuracy = accuracy.eval(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">      print(<span class="string">'step %d, training accuracy %g'</span> % (i, train_accuracy))</span><br><span class="line">    train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</span><br><span class="line"></span><br><span class="line">  print(<span class="string">'test accuracy %g'</span> % accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</span><br></pre></td></tr></table></figure>
<p>以上代码，在最终测试集上的准确率大概是99.2%。</p>
<p>目前为止，我们已经学会了用TensorFlow快捷地搭建、训练和评估一个复杂一点儿的深度学习模型。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MNIST机器学习入门]]></title>
      <url>/ml/tensorflow/mnist.html</url>
      <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本篇面向刚学习机器学习和TensorFlow的读者。如果您已经知道<code>MNIST</code>是什么，以及softmax（多项逻辑）回归是什么，那么您可能更喜欢这个<a href="/ml/tensorflow/deep-mnist.html">速度更快的教程</a>。确保 在开始任何教程之前<a href="https://www.tensorflow.org/versions/master/install/" target="_blank" rel="noopener">安装TensorFlow</a>。</p>
<p>当学习如何编程时，首先要做的就是打印“Hello World”。就像编程有Hello World，机器学习有MNIST。</p>
<p>MNIST是一个简单的计算机视觉数据集。它由这样的手写数字的图像组成：</p>
<p><img src="images/c0f27b05.png" alt=""></p>
<p>它也包含每一张图片对应的标签，告诉我们这个是数字几。比如，上面这四张图片的标签分别是5，0，4，1。</p>
<p>在此教程中，我们将训练一个机器学习模型用于预测图片里面的数字。我们的目的不是要设计一个世界一流的复杂模型 – 尽管我们会在之后给你源代码去实现一流的预测模型 – 而是要介绍下如何使用TensorFlow。所以，我们这里会从一个很简单的数学模型开始，它叫做<code>Softmax Regression</code>。</p>
<p>对应这个教程的实现代码很短，而且真正有意思的内容只包含在三行代码里面。但是，去理解包含在这些代码里面的设计思想是非常重要的：TensorFlow工作流程和机器学习的基本概念。因此，这个教程会很详细地介绍这些代码的实现原理。</p>
<h2 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h2><p>MNIST数据集的官网是<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">Yann LeCun’s website</a>。在这里，我们提供了一份python源代码用于自动下载和安装这个数据集。你可以下载<a href="https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py" target="_blank" rel="noopener">这份代码</a>，然后用下面的代码导入到你的项目里面，也可以直接复制粘贴到你的代码文件里面。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>下载下来的数据集被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。这样的切分很重要，在机器学习模型设计时必须有一个单独的测试数据集不用于训练而是用来评估这个模型的性能，从而更加容易把设计的模型推广到其他数据集上（泛化）。</p>
<p>正如前面提到的一样，每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels。</p>
<p>每一张图片包含28X28个像素点。我们可以用一个数字数组来表示这张图片：</p>
<p><img src="images/59921b9f.png" alt=""></p>
<p>我们把这个数组展开成一个向量，长度是 28x28 = 784。如何展开这个数组（数字间的顺序）不重要，只要保持各个图片采用相同的方式展开。从这个角度来看，MNIST数据集的图片就是在784维向量空间里面的点, 并且拥有比较复杂的结构 (提醒: 此类数据的可视化是计算密集型的)。</p>
<p>展平图片的数字数组会丢失图片的二维结构信息。这显然是不理想的，最优秀的计算机视觉方法会挖掘并利用这些结构信息，我们会在后续教程中介绍。但是在这个教程中我们忽略这些结构，所介绍的简单数学模型，softmax回归(softmax regression)，不会利用这些结构信息。</p>
<p>因此，在MNIST训练数据集中，mnist.train.images 是一个形状为 [60000, 784] 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。</p>
<p><img src="images/102.png" alt=""></p>
<p>相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， mnist.train.labels 是一个 [60000, 10] 的数字矩阵。</p>
<p><img src="images/103.png" alt=""></p>
<p>现在，我们准备好可以开始构建我们的模型啦！</p>
<h2 id="Softmax回归介绍"><a href="#Softmax回归介绍" class="headerlink" title="Softmax回归介绍"></a>Softmax回归介绍</h2><p>我们知道MNIST的每一张图片都表示一个数字，从0到9。我们希望得到给定图片代表每个数字的概率。比如说，我们的模型可能推测一张包含9的图片代表数字9的概率是80%但是判断它是8的概率是5%（因为8和9都有上半部分的小圆），然后给予它代表其他数字的概率更小的值。</p>
<p>这是一个使用softmax回归（softmax regression）模型的经典案例。softmax模型可以用来给不同的对象分配概率。即使在之后，我们训练更加精细的模型时，最后一步也需要用softmax来分配概率。</p>
<p>softmax回归（softmax regression）分两步：第一步</p>
<p>为了得到一张给定图片属于某个特定数字类的证据（evidence），我们对图片像素值进行加权求和。如果这个像素具有很强的证据说明这张图片不属于该类，那么相应的权值为负数，相反如果这个像素拥有有利的证据支持这张图片属于这个类，那么权值是正数。</p>
<p>下面的图片显示了一个模型学习到的图片上每个像素对于特定数字类的权值。红色代表负数权值，蓝色代表正数权值。</p>
<p><img src="images/104.png" alt=""></p>
<p>我们也需要加入一个额外的偏置量（bias），因为输入往往会带有一些无关的干扰量。因此对于给定的输入图片 x 它代表的是数字 i 的证据可以表示为</p>
<p><img src="images/12469775.png" alt=""></p>
<p>其中 <strong>W</strong><sub><em>i</em></sub> 代表权重，<strong>b</strong><sub><em>i</em></sub> 代表数字 <em>i</em> 类的偏置量，<em>j</em> 代表给定图片 <em>x</em> 的像素索引用于像素求和。然后用softmax函数可以把这些证据转换成概率<em>y</em>：</p>
<p><img src="images/fb2d299b.png" alt=""></p>
<p>这里的softmax可以看成是一个激励（activation）函数或者链接（link）函数，把我们定义的线性函数的输出转换成我们想要的格式，也就是关于10个数字类的概率分布。因此，给定一张图片，它对于每一个数字的吻合度可以被softmax函数转换成为一个概率值。softmax函数可以定义为：</p>
<p><img src="images/93226efb.png" alt=""></p>
<p>展开等式右边的子式，可以得到：</p>
<p><img src="images/8493a953.png" alt=""></p>
<p>但是更多的时候把softmax模型函数定义为前一种形式：把输入值当成幂指数求值，再正则化这些结果值。这个幂运算表示，更大的证据对应更大的假设模型（hypothesis）里面的乘数权重值。反之，拥有更少的证据意味着在假设模型里面拥有更小的乘数系数。假设模型里的权值不可以是0值或者负值。Softmax然后会正则化这些权重值，使它们的总和等于1，以此构造一个有效的概率分布。（更多的关于Softmax函数的信息，可以参考Michael Nieslen的书里面的这个部分，其中有关于softmax的可交互式的可视化解释。）</p>
<p>对于softmax回归模型可以用下面的图解释，对于输入的xs加权求和，再分别加上一个偏置量，最后再输入到softmax函数中：</p>
<p><img src="images/105.png" alt=""></p>
<p>如果把它写成一个等式，我们可以得到：</p>
<p><img src="images/106.png" alt=""></p>
<p>我们也可以用向量表示这个计算过程：用矩阵乘法和向量相加。这有助于提高计算效率。（也是一种更有效的思考方式）</p>
<p><img src="images/107.png" alt=""></p>
<p>更进一步，可以写成更加紧凑的方式：</p>
<p><img src="images/8dc654d7.png" alt=""></p>
<h2 id="实现回归模型"><a href="#实现回归模型" class="headerlink" title="实现回归模型"></a>实现回归模型</h2><p>为了用python实现高效的数值计算，我们通常会使用函数库，比如NumPy，会把类似矩阵乘法这样的复杂运算使用其他外部语言实现。不幸的是，从外部计算切换回Python的每一个操作，仍然是一个很大的开销。如果你用GPU来进行外部计算，这样的开销会更大。用分布式的计算方式，也会花费更多的资源用来传输数据。</p>
<p>TensorFlow也把复杂的计算放在python之外完成，但是为了避免前面说的那些开销，它做了进一步完善。Tensorflow不单独地运行单一的复杂计算，而是让我们可以先用图描述一系列可交互的计算操作，然后全部一起在Python之外运行。（这样类似的运行方式，可以在不少的机器学习库中看到。）</p>
<p>使用TensorFlow之前，首先导入它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<p>我们通过操作符号变量来描述这些可交互的操作单元，可以用下面的方式创建一个：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br></pre></td></tr></table></figure>
<p> <code>x</code> 不是一个特定的值，而是一个占位符 <code>placeholder</code>，我们在TensorFlow运行计算时输入这个值。我们希望能够输入任意数量的MNIST图像，每一张图展平成784维的向量。我们用2维的浮点数张量来表示这些图，这个张量的形状是[None，784 ]。（这里的 <code>None</code> 表示此张量的第一个维度可以是任何长度的。）</p>
<p>我们的模型也需要权重值和偏置量，当然我们可以把它们当做是另外的输入（使用占位符），但TensorFlow有一个更好的方法来表示它们：<code>Variable</code> 。 一个Variable代表一个可修改的张量，存在在TensorFlow的用于描述交互性操作的图中。它们可以用于计算输入值，也可以在计算中被修改。对于各种机器学习应用，一般都会有模型参数，可以用 <code>Variable</code> 表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>
<p>我们赋予 <code>tf.Variable</code> 不同的初值来创建不同的 <code>Variable</code>：在这里，我们都用全为零的张量来初始化 <code>W</code> 和 <code>b</code>。因为我们要学习W和b的值，它们的初值可以随意设置。</p>
<p>注意，<code>W</code> 的维度是[784，10]，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，每一位对应不同数字类。<code>b</code> 的形状是[10]，所以我们可以直接把它加到输出上面。</p>
<p>现在，我们可以实现我们的模型啦。只需要一行代码！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = tf.nn.softmax(tf.matmul(x,W) + b)</span><br></pre></td></tr></table></figure>
<p>首先，我们用 <code>tf.matmul(​​X，W)</code> 表示x乘以W，对应之前等式里面的 <strong>W</strong><sub><em>i</em></sub>，这里x是一个2维张量拥有多个输入。然后再加上b，把和输入到 <code>tf.nn.softmax</code> 函数里面。</p>
<p>至此，我们先用了几行简短的代码来设置变量，然后只用了一行代码来定义我们的模型。TensorFlow不仅仅可以使softmax回归模型计算变得特别简单，它也用这种非常灵活的方式来描述其他各种数值计算，从机器学习模型对物理学模拟仿真模型。一旦被定义好之后，我们的模型就可以在不同的设备上运行：计算机的CPU，GPU，甚至是手机！</p>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>为了训练我们的模型，我们首先需要定义一个指标来评估这个模型是好的。其实，在机器学习，我们通常定义指标来表示一个模型是坏的，这个指标称为成本（cost）或损失（loss），然后尽量最小化这个指标。但是，这两种方式是相同的。</p>
<p>一个非常常见的，非常漂亮的成本函数是“交叉熵”（cross-entropy）。交叉熵产生于信息论里面的信息压缩编码技术，但是它后来演变成为从博弈论到机器学习等其他领域里的重要技术手段。它的定义如下：</p>
<p><img src="images/b88334e9.png" alt=""></p>
<p><code>y</code> 是我们预测的概率分布, <code>y&#39;</code> 是实际的分布（我们输入的one-hot vector)。比较粗糙的理解是，交叉熵是用来衡量我们的预测用于描述真相的低效性。更详细的关于交叉熵的解释超出本教程的范畴，但是你很有必要好好理解它。</p>
<p>为了计算交叉熵，我们首先需要添加一个新的占位符用于输入正确值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>然后我们可以用 <img src="images/0b54e30c.png" alt="">计算交叉熵::</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y))</span><br></pre></td></tr></table></figure>
<p>首先，用 <code>tf.log</code> 计算 y 的每个元素的对数。接下来，我们把 y_ 的每一个元素和 <code>tf.log(y)</code> 的对应元素相乘。最后，用 <code>tf.reduce_sum</code> 计算张量的所有元素的总和。（注意，这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和。对于100个数据点的预测表现比单一数据点的表现能更好地描述我们的模型的性能。</p>
<p>现在我们知道我们需要我们的模型做什么啦，用TensorFlow来训练它是非常容易的。因为TensorFlow拥有一张描述你各个计算单元的图，它可以自动地使用<a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="noopener">反向传播算法(backpropagation algorithm)</a>来有效地确定你的变量是如何影响你想要最小化的那个成本值的。然后，TensorFlow会用你选择的优化算法来不断地修改变量以降低成本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<p>在这里，我们要求TensorFlow用梯度下降算法（gradient descent algorithm）以0.01的学习速率最小化交叉熵。梯度下降算法（gradient descent algorithm）是一个简单的学习过程，TensorFlow只需将每个变量一点点地往使成本不断降低的方向移动。当然TensorFlow也提供了<a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/api_docs/python/train.html" target="_blank" rel="noopener">其他许多优化算法</a>：只要简单地调整一行代码就可以使用其他的算法。</p>
<p>TensorFlow在这里实际上所做的是，它会在后台给描述你的计算的那张图里面增加一系列新的计算操作单元用于实现反向传播算法和梯度下降算法。然后，它返回给你的只是一个单一的操作，当运行这个操作时，它用梯度下降算法训练你的模型，微调你的变量，不断减少成本。</p>
<p>现在，我们可以在一个 <code>InteractiveSession</code> 里面启动模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.InteractiveSession()</span><br></pre></td></tr></table></figure>
<p>我们首先需要创建一个操作来初始化我们创建的变量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.global_variables_initializer().run()</span><br></pre></td></tr></table></figure>
<p>开始训练——我们将训练1000次。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">  sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</span><br></pre></td></tr></table></figure>
<p>该循环的每个步骤中，我们都会随机抓取训练数据中的100个批处理数据点，然后我们用这些数据点作为参数替换之前的占位符来运行train_step。</p>
<p>使用一小部分的随机数据来进行训练被称为随机训练（stochastic training）- 在这里更确切的说是随机梯度下降训练。在理想情况下，我们希望用我们所有的数据来进行每一步的训练，因为这能给我们更好的训练结果，但显然这需要很大的计算开销。所以，每一次训练我们可以使用不同的数据子集，这样做既可以减少计算开销，又可以最大化地学习到数据集的总体特性。</p>
<h2 id="评估我们的模型"><a href="#评估我们的模型" class="headerlink" title="评估我们的模型"></a>评估我们的模型</h2><p>那么我们的模型性能如何呢？</p>
<p>首先让我们找出那些预测正确的标签。<code>tf.argmax</code> 是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如 <code>tf.argmax(y,1)</code> 返回的是模型对于任一输入x预测到的标签值，而 <code>tf.argmax(y_,1)</code> 代表正确的标签，我们可以用 <code>tf.equal</code> 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这行代码会给我们一组布尔值。为了确定正确预测项的比例，我们可以把布尔值转换成浮点数，然后取平均值。例如，<code>[True, False, True, True]</code> 会变成 <code>[1,0,1,1]</code> ，取平均值后得到 0.75.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br></pre></td></tr></table></figure>
<p>最后，我们计算所学习到的模型在测试数据集上面的正确率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>这个最终结果值应该大约是92%。</p>
<p>这个结果好吗？嗯，并不太好。事实上，这个结果是很差的。这是因为我们仅仅使用了一个非常简单的模型。不过，做一些小小的改进，我们就可以得到97％的正确率。最好的模型甚至可以获得超过99.7％的准确率！（想了解更多信息，可以看看这个关于各种模型的<a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html" target="_blank" rel="noopener">性能对比列表</a>。)</p>
<p>比结果更重要的是，我们从这个模型中学习到的设计思想。不过，如果你仍然对这里的结果有点失望，可以查看<a href="/ml/tensorflow/deep-mnist.html">下一个教程</a>，在那里你可以学习如何用TensorFlow构建更加复杂的模型以获得更好的性能！</p>
<p>原文地址：<a href="https://www.tensorflow.org/versions/master/get_started/mnist/beginners" target="_blank" rel="noopener">MNIST For ML Beginners</a> 翻译：<a href="https://github.com/linbojin" target="_blank" rel="noopener">linbojin</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow运作方式入门]]></title>
      <url>/ml/tensorflow/tensorflow101.html</url>
      <content type="html"><![CDATA[<p>代码: <a href="Code: tensorflow/examples/tutorials/mnist/" target="_blank" rel="noopener">tensorflow/examples/tutorials/mnist/</a></p>
<p>本篇教程的目的，是向大家展示如何利用TensorFlow使用（经典）MNIST数据集训练并评估一个用于识别手写数字的简易前馈神经网络（feed-forward neural network）。我们的目标读者，是有兴趣使用TensorFlow的资深机器学习人士。</p>
<p>因此，撰写该系列教程并不是为了教大家机器学习领域的基础知识。</p>
<p>在学习本教程之前，请确保您已按照安装TensorFlow教程中的要求，完成了安装。</p>
<h2 id="教程使用的文件"><a href="#教程使用的文件" class="headerlink" title="教程使用的文件"></a>教程使用的文件</h2><p>本教程引用如下文件：</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>目的</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py" target="_blank" rel="noopener">mnist.py</a></td>
<td>构建一个完全连接（fully connected）的MINST模型所需的代码。</td>
</tr>
<tr>
<td><a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/fully_connected_feed.py" target="_blank" rel="noopener">fully_connected_feed.py</a></td>
<td>利用下载的数据集训练构建好的MNIST模型的主要代码，以数据反馈字典（feed dictionary）的形式作为输入模型。</td>
</tr>
</tbody>
</table>
<p>只需要直接运行<code>fully_connected_feed.py</code>文件，就可以开始训练：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python fully_connected_feed.py</span><br></pre></td></tr></table></figure>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>MNIST是机器学习领域的一个经典问题，指的是让机器查看一系列大小为28x28像素的手写数字灰度图像，并判断这些图像代表0-9中的哪一个数字。</p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>在<code>run_training()</code>方法的一开始，<code>input_data.read_data_sets()</code>函数会确保你的本地训练文件夹中，已经下载了正确的数据，然后将这些数据解压并返回一个含有<code>DataSet</code>实例的字典。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data)</span><br></pre></td></tr></table></figure>
<p>注意：<code>fake_data</code>标记是用于单元测试的，读者可以不必理会。</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>目的</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data_sets.train</code></td>
<td>55000个图像和标签（labels），作为主要训练集。</td>
</tr>
<tr>
<td><code>data_sets.validation</code></td>
<td>5000个图像和标签，用于迭代验证训练准确度。</td>
</tr>
<tr>
<td><code>data_sets.test</code></td>
<td>10000个图像和标签，用于最终测试训练准确度（trained accuracy）。</td>
</tr>
</tbody>
</table>
<h3 id="输入与占位符"><a href="#输入与占位符" class="headerlink" title="输入与占位符"></a>输入与占位符</h3><p><code>placeholder_inputs()</code>函数将生成两个<code>tf.placeholder</code>操作，定义传入图表中的shape参数，shape参数中包括<code>batch_size</code>值，后续还会将实际的训练用例传入图表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, mnist.IMAGE_PIXELS))</span><br><span class="line">labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))</span><br></pre></td></tr></table></figure>
<p>在训练循环（training loop）的后续步骤中，传入的整个图像和标签数据集会被切片，以符合每一个操作所设置的<code>batch_size</code>值，占位符操作将会填补以符合这个<code>batch_size</code>值。然后使用<code>feed_dict</code>参数，将数据传入<code>sess.run()</code>函数。</p>
<h2 id="构建图表-（Build-the-Graph）"><a href="#构建图表-（Build-the-Graph）" class="headerlink" title="构建图表 （Build the Graph）"></a>构建图表 （Build the Graph）</h2><p>在为数据创建占位符之后，就可以运行<code>mnist.py</code>文件，经过三阶段的模式函数操作：<code>inference()</code>， <code>loss()</code>，和<code>training()</code>。图表就构建完成了。</p>
<ol>
<li>inference() —— 尽可能地构建好图表，满足促使神经网络向前反馈并做出预测的要求。</li>
<li>loss() —— 往inference图表中添加生成损失（loss）所需要的操作（ops）。</li>
<li>training() —— 往损失图表中添加计算并应用梯度（gradients）所需的操作。</li>
</ol>
<p><img src="images/6725d75a.png" alt=""></p>
<h3 id="推理（Inference）"><a href="#推理（Inference）" class="headerlink" title="推理（Inference）"></a>推理（Inference）</h3><p>inference()函数会尽可能地构建图表，做到返回包含了预测结果（output prediction）的Tensor。</p>
<p>它接受图像占位符为输入，在此基础上借助<code>ReLu</code>(Rectified Linear Units)激活函数，构建一对完全连接层（layers），以及一个有着十个节点（node）、指明了输出logits模型的线性层。</p>
<p>每一层都创建于一个唯一的<code>tf.name_scope</code>之下，创建于该作用域之下的所有元素都将带有其前缀。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'hidden1'</span>):</span><br></pre></td></tr></table></figure>
<p>在定义的作用域中，每一层所使用的权重和偏差都在<code>tf.Variable</code>实例中生成，并且包含了各自期望的shape。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights = tf.Variable(</span><br><span class="line">    tf.truncated_normal([IMAGE_PIXELS, hidden1_units],</span><br><span class="line">                        stddev=<span class="number">1.0</span> / math.sqrt(float(IMAGE_PIXELS))),</span><br><span class="line">    name=<span class="string">'weights'</span>)</span><br><span class="line">biases = tf.Variable(tf.zeros([hidden1_units]),</span><br><span class="line">                     name=<span class="string">'biases'</span>)</span><br></pre></td></tr></table></figure>
<p>例如，当这些层是在<code>hidden1</code>作用域下生成时，赋予权重变量的独特名称将会是”<code>hidden1/weights</code>“。</p>
<p>每个变量在构建时，都会获得初始化操作（initializer ops）。</p>
<p>在这种最常见的情况下，通过<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/truncated_normal" target="_blank" rel="noopener">tf.truncated_normal</a>函数初始化权重变量，给赋予的shape则是一个二维tensor，其中第一个维度代表该层中权重变量所连接（connect from）的单元数量，第二个维度代表该层中权重变量所连接到的（connect to）单元数量。对于名叫hidden1的第一层，相应的维度则是<code>[IMAGE_PIXELS, hidden1_units]</code>，因为权重变量将图像输入连接到了hidden1层。<code>tf.truncated_normal</code>初始函数将根据所得到的均值和标准差，生成一个随机分布。</p>
<p>然后，通过<code>tf.zeros</code>函数初始化偏差变量（biases），确保所有偏差的起始值都是0，而它们的shape则是其在该层中所接到的（connect to）单元数量。</p>
<p>图表的三个主要操作，分别是两个<code>tf.nn.relu</code>操作，它们中嵌入了隐藏层所需的<code>tf.matmul</code>；以及logits模型所需的另外一个<code>tf.matmul</code>。三者依次生成，各自的<code>tf.Variable</code>实例则与输入占位符或下一层的输出tensor所连接。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)</span><br><span class="line">hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)</span><br><span class="line">logits = tf.matmul(hidden2, weights) + biases</span><br></pre></td></tr></table></figure>
<p>最后，程序会返回包含了输出结果的<code>logits</code>Tensor。</p>
<h3 id="损失（Loss）"><a href="#损失（Loss）" class="headerlink" title="损失（Loss）"></a>损失（Loss）</h3><p>loss()函数通过添加所需的损失操作，进一步构建图表。</p>
<p>首先, labels_placeholder 的值被转换为64位整数。然后, 添加一个 <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits" target="_blank" rel="noopener">tf.nn.sparse_softmax_cross_entropy_with_logits</a> op 以自动从 <code>labels_placeholder</code> 生成 1-hot 标签, 并将输出数与推断 <code>inference()</code> 函数与那些1-hot 签进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels = tf.to_int64(labels)</span><br><span class="line">cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">    labels=labels, logits=logits, name=<span class="string">'xentropy'</span>)</span><br></pre></td></tr></table></figure>
<p>然后，使用<code>tf.reduce_mean</code>函数，计算batch维度（第一维度）下交叉熵（cross entropy）的平均值，将将该值作为总损失。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = tf.reduce_mean(cross_entropy, name=<span class="string">'xentropy_mean'</span>)</span><br></pre></td></tr></table></figure>
<p>最后，程序会返回包含了损失值的Tensor。</p>
<blockquote>
<p>注意：交叉熵是信息理论中的概念，可以让我们描述如果基于已有事实，相信神经网络所做的推测最坏会导致什么结果。更多详情，请查阅博文《可视化信息理论》(<a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">http://colah.github.io/posts/2015-09-Visual-Information/</a>)</p>
</blockquote>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p><code>training()</code>函数添加了通过<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="noopener">梯度下降</a>（gradient descent）将损失最小化所需的操作。</p>
<p>首先，该函数从<code>loss()</code>函数中获取损失Tensor，将其交给<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/summary/scalar" target="_blank" rel="noopener">tf.scalar_summary</a>，该 op 用于在与 <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/summary/FileWriter" target="_blank" rel="noopener">tf.summary.FileWriter</a> (见下文) 一起使用时将汇总值（summary values）生成到事件文件（events file）中。在本篇教程中，每次写入汇总值时，它都会释放损失Tensor的当前值（snapshot value）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.scalar_summary(loss.op.name, loss)</span><br></pre></td></tr></table></figure>
<p>接下来，我们实例化一个<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/train/GradientDescentOptimizer" target="_blank" rel="noopener">tf.train.GradientDescentOptimizer</a>，负责按照所要求的学习效率（learning rate）应用梯度下降法（gradients）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure>
<p>之后，我们生成一个变量用于保存全局训练步骤（global training step）的数值，并使用<a href="tf.train.Optimizer.minimize">tf.train.Optimizer.minimize</a>函数更新系统中的三角权重（triangle weights）、增加全局步骤的操作。根据惯例，这个操作被称为 train_op，是TensorFlow会话（session）诱发一个完整训练步骤所必须运行的操作（见下文）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">train_op = optimizer.minimize(loss, global_step=global_step)</span><br></pre></td></tr></table></figure>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>一旦图表构建完毕，就通过<code>fully_connected_feed.py</code>文件中的用户代码进行循环地迭代式训练和评估。</p>
<h3 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h3><p>在<code>run_training()</code>这个函数的一开始，是一个Python语言中的with命令，这个命令表明所有已经构建的操作都要与默认的<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph" target="_blank" rel="noopener">tf.Graph</a>全局实例关联起来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br></pre></td></tr></table></figure>
<p><code>tf.Graph</code>实例是一系列可以作为整体执行的操作。TensorFlow的大部分场景只需要依赖默认图表一个实例即可。</p>
<p>利用多个图表的更加复杂的使用场景也是可能的，但是超出了本教程的范围。</p>
<h3 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h3><p>完成全部的构建准备、生成全部所需的操作之后，我们就可以创建一个<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/Session" target="_blank" rel="noopener">tf.Session</a>，用于运行图表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure>
<p>另外，也可以利用with代码块生成<code>Session</code>，限制作用域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br></pre></td></tr></table></figure>
<p>Session函数中没有传入参数，表明该代码将会依附于（如果还没有创建会话，则会创建新的会话）默认的本地会话。</p>
<p>生成会话之后，所有<code>tf.Variable</code>实例都会立即通过调用各自初始化操作中的<a href="tf.Session.run">tf.Session.run</a>函数进行初始化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<p><code>sess.run()</code>方法将会运行图表中与作为参数传入的操作相对应的完整子集。在初次调用时，init操作只包含了变量初始化程序<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/group" target="_blank" rel="noopener">tf.group</a>。图表的其他部分不会在这里，而是在下面的训练循环运行。</p>
<h3 id="训练循环"><a href="#训练循环" class="headerlink" title="训练循环"></a>训练循环</h3><p>完成会话中变量的初始化之后，就可以开始训练了。</p>
<p>训练的每一步都是通过用户代码控制，而能实现有效训练的最简单循环就是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    sess.run(train_op)</span><br></pre></td></tr></table></figure>
<p>然而，本教程中的例子要更为复杂一点，原因是我们必须把输入的数据根据每一步的情况进行切分，以匹配之前生成的占位符。</p>
<h4 id="向图表提供反馈"><a href="#向图表提供反馈" class="headerlink" title="向图表提供反馈"></a>向图表提供反馈</h4><p>执行每一步时，我们的代码会生成一个反馈字典（feed dictionary），其中包含对应步骤中训练所要使用的例子，这些例子的哈希键就是其所代表的占位符操作。</p>
<p><code>fill_feed_dict</code>函数会查询给定的<code>DataSet</code>，索要下一批次<code>batch_size</code>的图像和标签，与占位符相匹配的Tensor则会包含下一批次的图像和标签。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,</span><br><span class="line">                                               FLAGS.fake_data)</span><br></pre></td></tr></table></figure>
<p>然后，以占位符为哈希键，创建一个Python字典对象，键值则是其代表的反馈Tensor。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feed_dict = &#123;</span><br><span class="line">    images_placeholder: images_feed,</span><br><span class="line">    labels_placeholder: labels_feed,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个字典随后作为<code>feed_dict</code>参数，传入<code>sess.run()</code>函数中，为这一步的训练提供输入样例。</p>
<h4 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h4><p>在运行<code>sess.run</code>函数时，要在代码中明确其需要获取的两个值：<code>[train_op, loss]</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    feed_dict = fill_feed_dict(data_sets.train,</span><br><span class="line">                               images_placeholder,</span><br><span class="line">                               labels_placeholder)</span><br><span class="line">    _, loss_value = sess.run([train_op, loss],</span><br><span class="line">                             feed_dict=feed_dict)</span><br></pre></td></tr></table></figure>
<p>因为要获取这两个值，<code>sess.run()</code>会返回一个有两个元素的元组。其中每一个Tensor对象，对应了返回的元组中的numpy数组，而这些数组中包含了当前这步训练中对应Tensor的值。由于<code>train_op</code>并不会产生输出，其在返回的元祖中的对应元素就是<code>None</code>，所以会被抛弃。但是，如果模型在训练中出现偏差，<code>loss</code>Tensor的值可能会变成NaN，所以我们要获取它的值，并记录下来。</p>
<p>假设训练一切正常，没有出现NaN，训练循环会每隔100个训练步骤，就打印一行简单的状态文本，告知用户当前的训练状态。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Step %d: loss = %.2f (%.3f sec)'</span> % (step, loss_value, duration)</span><br></pre></td></tr></table></figure>
<h4 id="状态可视化"><a href="#状态可视化" class="headerlink" title="状态可视化"></a>状态可视化</h4><p>为了释放<a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/summaries_and_tensorboard.html" target="_blank" rel="noopener">TensorBoard</a>所使用的事件文件（events file），所有的即时数据（在这里只有一个）都要在图表构建阶段合并至一个操作（op）中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary = tf.summary.merge_all()</span><br></pre></td></tr></table></figure>
<p>在创建好会话（session）之后，可以实例化一个<code>tf.train.SummaryWriter</code>，用于写入包含了图表本身和即时数据具体值的事件文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary_writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)</span><br></pre></td></tr></table></figure>
<p>最后，每次运行<code>summary</code>时，都会往事件文件中写入最新的即时数据，函数的输出会传入事件文件读写器（writer）的<code>add_summary()</code>函数。。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary_str = sess.run(summary, feed_dict=feed_dict)</span><br><span class="line">summary_writer.add_summary(summary_str, step)</span><br></pre></td></tr></table></figure>
<p>事件文件写入完毕之后，可以就训练文件夹打开一个TensorBoard，查看即时数据的情况。</p>
<p><img src="images/7e0bb7f7.png" alt=""></p>
<p>注意：了解更多如何构建并运行TensorBoard的信息，请查看相关教程<a href="https://www.tensorflow.org/versions/master/get_started/summaries_and_tensorboard" target="_blank" rel="noopener">Tensorboard：训练过程可视化</a>。</p>
<h4 id="保存检查点（checkpoint）"><a href="#保存检查点（checkpoint）" class="headerlink" title="保存检查点（checkpoint）"></a>保存检查点（checkpoint）</h4><p>为了得到可以用来后续恢复模型以进一步训练或评估的检查点文件（checkpoint file），我们实例化一个<code>tf.train.Saver</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure>
<p>在训练循环中，将定期调用<code>tf.train.Saver.save</code>方法，向训练文件夹中写入包含了当前所有可训练变量值得检查点文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver.save(sess, FLAGS.train_dir, global_step=step)</span><br></pre></td></tr></table></figure>
<p>这样，我们以后就可以使用<code>saver.restore()</code>方法，重载模型的参数，继续训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver.restore(sess, FLAGS.train_dir)</span><br></pre></td></tr></table></figure>
<h2 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h2><p>每隔一千个训练步骤，我们的代码会尝试使用训练数据集与测试数据集，对模型进行评估。<code>do_eval</code>函数会被调用三次，分别使用训练数据集、验证数据集合测试数据集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'Training Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.train)</span><br><span class="line">print(<span class="string">'Validation Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.validation)</span><br><span class="line">print(<span class="string">'Test Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.test)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，更复杂的使用场景通常是，先隔绝 <code>data_sets.test</code> 测试数据集，只有在大量的超参数优化调整（hyperparameter tuning）之后才进行检查。但是，由于MNIST问题比较简单，我们在这里一次性评估所有的数据。</p>
</blockquote>
<h3 id="构建评估图表（Eval-Graph）"><a href="#构建评估图表（Eval-Graph）" class="headerlink" title="构建评估图表（Eval Graph）"></a>构建评估图表（Eval Graph）</h3><p>在进入训练循环之前，我们应该先调用<code>mnist.py</code>文件中的<code>evaluation</code>函数，传入的logits和标签参数要与<code>loss()</code>的一致。这样做事为了先构建Eval操作。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_correct = mnist.evaluation(logits, labels_placeholder)</span><br></pre></td></tr></table></figure></p>
<p><code>evaluation</code>函数会生成<code>tf.nn.in_top_k</code> 操作，如果在K个最有可能的预测中可以发现真的标签，那么这个操作就会将模型输出标记为正确。在本文中，我们把<code>K</code>的值设置为1，也就是只有在预测是真的标签时，才判定它是正确的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_correct = tf.nn.in_top_k(logits, labels, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="评估图表的输出（Eval-Output）"><a href="#评估图表的输出（Eval-Output）" class="headerlink" title="评估图表的输出（Eval Output）"></a>评估图表的输出（Eval Output）</h3><p>之后，我们可以创建一个循环，往其中添加<code>feed_dict</code>，并在调用<code>sess.run()</code>函数时传入<code>eval_correct</code>操作，目的就是用给定的数据集评估模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(steps_per_epoch):</span><br><span class="line">    feed_dict = fill_feed_dict(data_set,</span><br><span class="line">                               images_placeholder,</span><br><span class="line">                               labels_placeholder)</span><br><span class="line">    true_count += sess.run(eval_correct, feed_dict=feed_dict)</span><br></pre></td></tr></table></figure>
<p><code>true_count</code>变量会累加所有<code>in_top_k</code>操作判定为正确的预测之和。接下来，只需要将正确测试的总数，除以例子总数，就可以得出准确率了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">precision = true_count / num_examples</span><br><span class="line">print(<span class="string">'  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f'</span> %</span><br><span class="line">      (num_examples, true_count, precision))</span><br></pre></td></tr></table></figure>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Tensorflow入门]]></title>
      <url>/ml/tensorflow/index.html</url>
      <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本指南让您开始在TensorFlow中编程。在使用本指南之前， 请先 <a href="https://www.tensorflow.org/versions/master/install/index" target="_blank" rel="noopener">安装TensorFlow</a>。为了从本指南中获得最大的帮助，您应该先了解以下内容：</p>
<ul>
<li>如何用Python编程。</li>
<li>至少有一点关于数组。</li>
<li>最理想的情况下是对机器学习有些许认知。但是，如果您对机器学习知之甚少，那么这仍然是您应该阅读的第一本指南。</li>
</ul>
<p>TensorFlow 提供了多个 api。最低级别的 API–<code>TensorFlow Core</code> 为您提供完整的程序控制。我们建议将 <code>TensorFlow Core</code> 作为机器学习研究人员和其他需要良好水平的人的控制模型。更高层次的 api 是建立在 <code>TensorFlow Core</code> 之上的。这些更高层次的 api 通常比 <code>TensorFlow Core</code> 更容易学习和使用。此外, 较高级别的 api 重复任务更容易, 并且在不同用户之间更加一致。像高级 API比如 <code>tf.estimator</code> 可以帮助您管理数据集、估计、培训和推断。</p>
<p>本指南从 <code>TensorFlow Core</code> 的教程开始。稍后, 我们将演示如何在 <code>tf.estimator</code> 中实现相同的模型。了解 <code>TensorFlow Core</code> 原理有很大作用, 当您使用更紧凑的高级 API 时, 更清楚内部事物是如何工作的。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>使用图 (graph) 来表示计算任务.</li>
<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>
<li>使用 tensor 表示数据.</li>
<li>通过 变量 (Variable) 维护状态.</li>
<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>
</ul>
<h3 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors(张量)"></a>Tensors(张量)</h3><p>TensorFlow 中数据的中心单位是 tensor。tensor 由一组形成于任意维数数组的原始值组成。tensor 的 rank(秩) 是它的维数。下面是 tensor 的一些示例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">3</span> <span class="comment"># 规模最小的张量是0阶张量，即标量，也就是一个数。</span></span><br><span class="line">[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>] <span class="comment"># 把一些数有序的排列起来，就形成了1阶张量，也就是一个向量</span></span><br><span class="line">[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]] <span class="comment"># 把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵,</span></span><br><span class="line">[[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]], [[<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]]] <span class="comment"># 把矩阵摞起来，就是3阶张量，我们可以称为一个立方体</span></span><br></pre></td></tr></table></figure>
<p>张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量，沿着第1个轴你看到的是[1,3]，[2,4]两个向量。</p>
<h2 id="TensorFlow-核心教程"><a href="#TensorFlow-核心教程" class="headerlink" title="TensorFlow 核心教程"></a>TensorFlow 核心教程</h2><h3 id="导入-TensorFlow-模块"><a href="#导入-TensorFlow-模块" class="headerlink" title="导入 TensorFlow 模块"></a>导入 TensorFlow 模块</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<p> 这使 Python 可以访问 TensorFlow 的所有类、方法和符号。大多数文档假定您已经完成了此操作。</p>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>你可能会想到TensorFlow核心程序由两个独立的部分组成：</p>
<ul>
<li>构建计算图</li>
<li>运行计算图</li>
</ul>
<p>一个计算图是将一系列的 TensorFlow 操作(<code>Operation</code>)排列成一个节点图。让我们建立一个简单的计算图。每个节点以零或更多张量作为输入, 并生成一个张量作为输出。有一种类型的节点是常量。像所有的 TensorFlow 常量一样, 它不需要输入, 并且输出一个它在内部存储的值。我们可以创建两个浮点张量 node1 和 node2 如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">node1 = tf.constant(<span class="number">3.0</span>, dtype=tf.float32)</span><br><span class="line">node2 = tf.constant(<span class="number">4.0</span>) <span class="comment"># also tf.float32 implicitly</span></span><br><span class="line">print(node1, node2)</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Tensor(<span class="string">"Const:0"</span>, shape=(), dtype=float32) Tensor(<span class="string">"Const_1:0"</span>, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<p>请注意, 打印节点不会像您预期的那样输出值3.0 和4.0，相反, 它们是在计算时将分别产生3.0 和4.0 的节点，要实际评估节点, 我们必须在一个会话(<code>session</code>)中运行计算图，会话封装了 TensorFlow 运行时的控制和状态。</p>
<p>下面的代码创建一个 <code>session</code> 对象, 然后调用其 run 方法以运行足够的计算图来计算 node1 和 node2。通过在会话(<code>session</code>)中运行计算图, 如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run([node1, node2]))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">3.0</span>, <span class="number">4.0</span>]</span><br></pre></td></tr></table></figure></p>
<p>我们可以通过将张量节点与操作结合起来构建更复杂的计算（操作也是节点）。例如，我们可以添加两个常量节点并生成一个新的图，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line">node3 = tf.add(node1, node2)</span><br><span class="line">print(<span class="string">"node3:"</span>, node3)</span><br><span class="line">print(<span class="string">"sess.run(node3):"</span>, sess.run(node3))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">node3: Tensor(<span class="string">"Add:0"</span>, shape=(), dtype=float32)</span><br><span class="line">sess.run(node3): <span class="number">7.0</span></span><br></pre></td></tr></table></figure></p>
<p>TensorFlow 提供了一种称为 <code>TensorBoard</code> 的实用程序, 可以显示计算图的图片。下面是一个截图, 展示了 <code>TensorBoard</code> 如何直观地显示图:</p>
<p><img src="images/28d118c8.png" alt=""></p>
<p>事实上，这张图并不特别有趣，因为它总是产生一个固定的结果。一个图可以接受外部输入的参数，称为占位符(<code>placeholder</code>)。占位符是稍后提供值的保证。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = tf.placeholder(tf.float32)</span><br><span class="line">b = tf.placeholder(tf.float32)</span><br><span class="line">adder_node = a + b</span><br></pre></td></tr></table></figure>
<p>上面三行有点像函数或 lambda, 我们在其中定义了两个输入参数 (a 和 b), 然后对它们进行操作。我们可以用多个输入来计算这个图, 它使用 feed_dict 参数到 run 方法来给占位符提供具体值:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(sess.run(adder_node, &#123;a: <span class="number">3</span>, b: <span class="number">4.5</span>&#125;))</span><br><span class="line">print(sess.run(adder_node, &#123;a: [<span class="number">1</span>, <span class="number">3</span>], b: [<span class="number">2</span>, <span class="number">4</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">7.5</span></span><br><span class="line">[<span class="number">3.</span> <span class="number">7.</span>]</span><br></pre></td></tr></table></figure></p>
<p>在 TensorBoard 中, 图形如下所示:</p>
<p><img src="images/0d2edff3.png" alt=""></p>
<p>我们可以通过添加另一个操作使计算图更加复杂。例如,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_and_triple = adder_node * <span class="number">3.</span></span><br><span class="line">print(sess.run(add_and_triple, &#123;a: <span class="number">3</span>, b: <span class="number">4.5</span>&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">22.5</span></span><br></pre></td></tr></table></figure></p>
<p>计算图在 TensorBoard 中如下所示:</p>
<p><img src="images/00ec712b.png" alt=""></p>
<p>在机器学习中, 我们通常需要一个可以接受任意输入的模型, 比如上面的一个。为了使模型训练, 我们需要能够修改图形, 以获得相同的输入新的输出。变量(<code>Variables</code>)允许我们向图中添加训练参数。它们是用类型和初始值构造的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W*x + b</span><br></pre></td></tr></table></figure>
<p>常量在调用 <code>tf.constant</code> 时初始化, 它们的值永远不会改变。相反, 当调用 <code>tf.Variable</code> 时, 变量不会初始化。变量.若要初始化 TensorFlow 程序中的所有变量, 必须显式调用特殊操作, 如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<p>重要的是 <code>init</code> 是一个 TensorFlow 子图, 它是初始化所有的全局变量的句柄。在我们调用  <code>sess.run</code> 之前, 变量是未初始化的。</p>
<p>由于 x 是占位符, 因此我们可以同时对 x 的多个值进行 linear_model 计算, 如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(sess.run(linear_model, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0.</span>         <span class="number">0.3</span>        <span class="number">0.6</span>        <span class="number">0.90000004</span>]</span><br></pre></td></tr></table></figure></p>
<p>我们已经建立了一个模型, 但我们还不知道它有多好。为了评估培训数据的模型, 我们需要一个 y 占位符来提供所需的值, 我们需要写一个损失函数。</p>
<p>损失函数(<code>loss function</code>)用于测量当前模型与所提供数据之间的距离。我们将使用一个标准的线性回归模型, 总结了目前模型和提供数据之间的方差之和。<code>linear_model y</code> 创建一个向量, 其中每个元素都是误差相应的delta。我们调用 <code>tf.square</code> 来给误差做平方计算。然后，然后,我们使用 <code>tf.reduce_sum</code> 来创建一个标量用来计算所有的平方差之和来将所有error实例抽象出来:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line">squared_deltas = tf.square(linear_model - y)</span><br><span class="line">loss = tf.reduce_sum(squared_deltas)</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">23.66</span></span><br></pre></td></tr></table></figure></p>
<p>我们可以通过将 W 和 b 的值重新指派为-1 和1的完美值来手动改进此项。变量初始化的值为 <code>tf.Variable</code> 提供 。可以使用 <code>tf.assign</code> 进行改变。例如，w＝1和B＝1是我们模型的最佳参数。我们可以相应地改变w和b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fixW = tf.assign(W, [<span class="number">-1.</span>])</span><br><span class="line">fixb = tf.assign(b, [<span class="number">1.</span>])</span><br><span class="line">sess.run([fixW, fixb])</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[array([<span class="number">-1.</span>], dtype=float32), array([<span class="number">1.</span>], dtype=float32)]</span><br><span class="line"><span class="number">0.0</span></span><br></pre></td></tr></table></figure></p>
<p>我们猜测 W 和 b 的 “完美” 值, 但机器学习的全部意义是自动找到正确的模型参数。在下一节中, 我们将演示如何完成此操作。</p>
<h2 id="tf-train-API"><a href="#tf-train-API" class="headerlink" title="tf.train API"></a>tf.train API</h2><p>关于机器学习的完整讨论超出了本教程的范围。然而, TensorFlow 提供优化器(<code>optimizers</code>), 慢慢地改变每个变量, 以尽量减少损失函数(<code>loss function</code>)。最简单的优化器是梯度下降(<code>gradient descent</code>)。它根据该变量的损失函数的大小来修正每个变量。一般而言, 手工计算 <code>symbolic derivatives</code> 是单调乏味且容易出错的。因此, TensorFlow 可以自动产生 <code>derivatives</code> , 只给出一个描述的模型使用函数 <code>tf.gradients</code> 。为了简单起见, 优化器(<code>optimizers</code>) 通常为您执行此操作。例如,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess.run(init) <span class="comment"># reset variables to incorrect defaults.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  sess.run(train, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;)</span><br><span class="line"></span><br><span class="line">print(sess.run([W, b]))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[array([<span class="number">-0.9999969</span>], dtype=float32), array([<span class="number">0.9999908</span>], dtype=float32)]</span><br></pre></td></tr></table></figure></p>
<p>现在我们已经完成了实际上的机器学习!虽然这个简单的线性回归模型不需要太多的 <code>TensorFlow core</code> 代码, 但使用更复杂的模型和方法将数据导入到模型中, 这就必须有更多的代码。因此, TensorFlow 为常见的模式、结构和功能(<code>patterns,structures,and functionality</code>)提供了更高级别的抽象(<code>abstractions</code>)。在下一节中, 我们将学习如何使用这些抽象。</p>
<h3 id="完成代码"><a href="#完成代码" class="headerlink" title="完成代码"></a>完成代码</h3><p>已完成的训练线性回归模型如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model parameters</span></span><br><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line"><span class="comment"># Model input and output</span></span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W*x + b</span><br><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_sum(tf.square(linear_model - y)) <span class="comment"># sum of the squares</span></span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training data</span></span><br><span class="line">x_train = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">y_train = [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]</span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init) <span class="comment"># initialize variables with incorrect defaults.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  sess.run(train, &#123;x: x_train, y: y_train&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate training accuracy</span></span><br><span class="line">curr_W, curr_b, curr_loss = sess.run([W, b, loss], &#123;x: x_train, y: y_train&#125;)</span><br><span class="line">print(<span class="string">"W: %s b: %s loss: %s"</span>%(curr_W, curr_b, curr_loss))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W: [<span class="number">-0.9999969</span>] b: [<span class="number">0.9999908</span>] loss: <span class="number">5.6999738e-11</span></span><br></pre></td></tr></table></figure></p>
<p>请注意, 损失是一个非常小的数字 (非常接近零)。如果您运行此程序, 您的损失可能与前面提到的损失完全相同, 因为模型是用伪随机值初始化的。</p>
<p>这个更复杂的程序仍然可以在 TensorBoard 中可视化:</p>
<p><img src="images/c1f79ff6.png" alt=""></p>
<h2 id="tf-estimator"><a href="#tf-estimator" class="headerlink" title="tf.estimator"></a>tf.estimator</h2><p><code>tf.estimator</code> 是一个高级TensorFlow库,用于简化机器学习的机制,其内容包括:</p>
<ul>
<li>训练循环</li>
<li>赋值循环</li>
<li>管理数据集</li>
</ul>
<p><code>tf.estimator</code> 定义了许多常见的模型。</p>
<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p>请注意使用 <code>tf.estimator</code> 使得线性回归变得多么简单:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># NumPy is often used to load, manipulate and preprocess data.</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features. We only have one numeric feature. There are many</span></span><br><span class="line"><span class="comment"># other types of columns that are more complicated and useful.</span></span><br><span class="line">feature_columns = [tf.feature_column.numeric_column(<span class="string">"x"</span>, shape=[<span class="number">1</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># An estimator is the front end to invoke training (fitting) and evaluation</span></span><br><span class="line"><span class="comment"># (inference). There are many predefined types like linear regression,</span></span><br><span class="line"><span class="comment"># linear classification, and many neural network classifiers and regressors.</span></span><br><span class="line"><span class="comment"># The following code provides an estimator that does linear regression.</span></span><br><span class="line">estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow provides many helper methods to read and set up data sets.</span></span><br><span class="line"><span class="comment"># Here we use two data sets: one for training and one for evaluation</span></span><br><span class="line"><span class="comment"># We have to tell the function how many batches</span></span><br><span class="line"><span class="comment"># of data (num_epochs) we want and how big each batch should be.</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can invoke 1000 training steps by invoking the method and passing the</span></span><br><span class="line"><span class="comment"># training data set.</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br></pre></td></tr></table></figure>
<p>当它运行时，可能会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train metrics: &#123;<span class="string">'average_loss'</span>: <span class="number">1.0863615e-08</span>, <span class="string">'loss'</span>: <span class="number">4.345446e-08</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br><span class="line">eval metrics: &#123;<span class="string">'average_loss'</span>: <span class="number">0.002535033</span>, <span class="string">'loss'</span>: <span class="number">0.010140132</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>请注意, 我们的 eval 数据有更高的损失, 但它仍然接近于零。这意味着我们正在正确学习。</p>
<h3 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h3><p><code>tf.estimator</code> 不会将你禁锢在它预设的模型中。假设我们想要创建一个自定义模型。我们仍然可以通过 <code>tf.estimator</code> 保持高度抽象的数据集,喂养,训练等。为了说明,我们将展示如何用低级TensorFlow API实现自己的等效线性回归模型。</p>
<p>要使用 <code>tf.estimator</code> 定义一个自定义模型。我们需要使用 <code>tf.estimator.Estimator</code>。<code>tf.estimator.LinearRegressor</code> 实际上是 <code>tf.estimator.Estimator</code> 的一个子类。我们只是给 <code>Estimator</code> 提供一个函数 <code>model_fn</code> 来告诉 <code>tf.estimator</code> 怎样定义预测,训练步骤,和损失，而不是生成子类 <code>Estimator</code>。代码如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features, we only have one real-valued feature</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode)</span>:</span></span><br><span class="line">  <span class="comment"># Build a linear model and predict values</span></span><br><span class="line">  W = tf.get_variable(<span class="string">"W"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  b = tf.get_variable(<span class="string">"b"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  y = W*features[<span class="string">'x'</span>] + b</span><br><span class="line">  <span class="comment"># Loss sub-graph</span></span><br><span class="line">  loss = tf.reduce_sum(tf.square(y - labels))</span><br><span class="line">  <span class="comment"># Training sub-graph</span></span><br><span class="line">  global_step = tf.train.get_global_step()</span><br><span class="line">  optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">  train = tf.group(optimizer.minimize(loss),</span><br><span class="line">                   tf.assign_add(global_step, <span class="number">1</span>))</span><br><span class="line">  <span class="comment"># EstimatorSpec connects subgraphs we built to the</span></span><br><span class="line">  <span class="comment"># appropriate functionality.</span></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">      mode=mode,</span><br><span class="line">      predictions=y,</span><br><span class="line">      loss=loss,</span><br><span class="line">      train_op=train)</span><br><span class="line"></span><br><span class="line">estimator = tf.estimator.Estimator(model_fn=model_fn)</span><br><span class="line"><span class="comment"># define our data sets</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7.</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train metrics: &#123;<span class="string">'loss'</span>: <span class="number">1.08032486e-10</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br><span class="line">eval metrics: &#123;<span class="string">'loss'</span>: <span class="number">0.010101897</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>注意，自定义model()函数的内容和低级API的手动循环训练模型十分相似。</p>
<h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>现在您有了TensorFlow的基础知识。我们有几个教程,您可以看看了解更多信息。如果您是初学者的话，请看<a href="/ml/tensorflow/mnist.html">MNIST机器学习入门</a>, 否则看<a href="/ml/tensorflow/deep-mnist.html">深入探索MNIST</a>.</p>
]]></content>
    </entry>
    
  
</search>
