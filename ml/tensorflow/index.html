

<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <title>Tensorflow入门 — Itimor's Book</title>
    <meta charset="utf-8">
    <meta name="description" content="Itimor's Book">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Tensorflow入门 — Itimor's Book">
    <meta property="og:description" content="Itimor's Book">
    <meta property="og:image" content="https://itimor.github.io//images/logo.png">

    <link rel="icon" type="image/png" sizes="32x32" href="/images/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/images/icons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/icons/favicon-16x16.png">
    <link rel="icon" href="/images/logo.png" type="image/png">
      
    <meta name="baidu-site-verification" content="ah99c7kYSG" />
    <meta name="msapplication-TileColor" content="#4fc08d">
    <meta name="theme-color" content="#4fc08d">
    <meta name="msapplication-config" content="browserconfig.xml">


    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- main page styles -->
    <link rel="stylesheet" href="/css/page.css">

    <!-- this needs to be loaded before guide's inline scripts -->
    <script>window.PAGE_TYPE = "tensorflow"</script>

    <!-- ga -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', '', 'itimor.github.io');
      ga('send', 'pageview');
    </script>
  </head>
  <body class="docs">
    <div id="mobile-bar" >
      <a class="menu-button"></a>
      <a class="logo" href="/"></a>
    </div>
    <div id="header">
  <a id="logo" href="/">
   <!-- <img src="/images/logo.png"> -->
    <span>Itimor's Book</span>
  </a>
  <ul id="nav">
    <li>
  <form id="search-form">
    <input type="text" id="local-search-input" class="local-search-input">
    <div id="local-search-result" class="local-search-result"></div>
  </form>
</li>
<li class="nav-dropdown-container learn">
  <a class="nav-link">机器学习</a><span class="arrow"></span>
  <ul class="nav-dropdown">
    <li><ul>
      <li><a href="/ml/tensorflow/" class="nav-link current">Tensorflow</a></li>
      <li><a href="/ml/mllib/" class="nav-link">基础包介绍</a></li>
    </ul></li>
  </ul>
</li>

<li>
  <a href="/about/" class="nav-link team">about</a>
</li>
  </ul>
</div>
    
      <div id="main" class="fix-sidebar">
        
          
  <div class="sidebar">
  <div class="sidebar-inner">
    <ul class="main-menu">
      <li>
  <form id="search-form">
    <input type="text" id="local-search-input" class="local-search-input">
    <div id="local-search-result" class="local-search-result"></div>
  </form>
</li>
<li class="nav-dropdown-container learn">
  <a class="nav-link">机器学习</a><span class="arrow"></span>
  <ul class="nav-dropdown">
    <li><ul>
      <li><a href="/ml/tensorflow/" class="nav-link current">Tensorflow</a></li>
      <li><a href="/ml/mllib/" class="nav-link">基础包介绍</a></li>
    </ul></li>
  </ul>
</li>

<li>
  <a href="/about/" class="nav-link team">about</a>
</li>
    </ul>
    <div class="list">
      <h2>
        
        Tensorflow教程
      </h2>
      <ul class="menu-root">
  
    
    
    
    <li>
      <a href="/ml/tensorflow/index.html" class="sidebar-link current">Tensorflow入门</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/mnist.html" class="sidebar-link">MNIST机器学习入门</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/deep-mnist.html" class="sidebar-link">深入探索MNIST</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/tensorflow101.html" class="sidebar-link">TensorFlow运作方式入门</a>
    </li>
  
  
</ul>

    </div>
  </div>
</div>


<div class="content tensorflow with-sidebar ">
  
    
  
  
    <h1>Tensorflow入门</h1>
  
  <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本指南让您开始在TensorFlow中编程。在使用本指南之前， 请先 <a href="https://www.tensorflow.org/versions/master/install/index" target="_blank" rel="noopener">安装TensorFlow</a>。为了从本指南中获得最大的帮助，您应该先了解以下内容：</p>
<ul>
<li>如何用Python编程。</li>
<li>至少有一点关于数组。</li>
<li>最理想的情况下是对机器学习有些许认知。但是，如果您对机器学习知之甚少，那么这仍然是您应该阅读的第一本指南。</li>
</ul>
<p>TensorFlow 提供了多个 api。最低级别的 API–<code>TensorFlow Core</code> 为您提供完整的程序控制。我们建议将 <code>TensorFlow Core</code> 作为机器学习研究人员和其他需要良好水平的人的控制模型。更高层次的 api 是建立在 <code>TensorFlow Core</code> 之上的。这些更高层次的 api 通常比 <code>TensorFlow Core</code> 更容易学习和使用。此外, 较高级别的 api 重复任务更容易, 并且在不同用户之间更加一致。像高级 API比如 <code>tf.estimator</code> 可以帮助您管理数据集、估计、培训和推断。</p>
<p>本指南从 <code>TensorFlow Core</code> 的教程开始。稍后, 我们将演示如何在 <code>tf.estimator</code> 中实现相同的模型。了解 <code>TensorFlow Core</code> 原理有很大作用, 当您使用更紧凑的高级 API 时, 更清楚内部事物是如何工作的。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>使用图 (graph) 来表示计算任务.</li>
<li>在被称之为 会话 (Session) 的上下文 (context) 中执行图.</li>
<li>使用 tensor 表示数据.</li>
<li>通过 变量 (Variable) 维护状态.</li>
<li>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</li>
</ul>
<h3 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors(张量)"></a>Tensors(张量)</h3><p>TensorFlow 中数据的中心单位是 tensor。tensor 由一组形成于任意维数数组的原始值组成。tensor 的 rank(秩) 是它的维数。下面是 tensor 的一些示例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">3</span> <span class="comment"># 规模最小的张量是0阶张量，即标量，也就是一个数。</span></span><br><span class="line">[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>] <span class="comment"># 把一些数有序的排列起来，就形成了1阶张量，也就是一个向量</span></span><br><span class="line">[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]] <span class="comment"># 把一组向量有序的排列起来，就形成了2阶张量，也就是一个矩阵,</span></span><br><span class="line">[[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]], [[<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]]] <span class="comment"># 把矩阵摞起来，就是3阶张量，我们可以称为一个立方体</span></span><br></pre></td></tr></table></figure>
<p>张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量，有两个维度或轴，沿着第0个轴（为了与python的计数方式一致，本文档维度和轴从0算起）你看到的是[1,2]，[3,4]两个向量，沿着第1个轴你看到的是[1,3]，[2,4]两个向量。</p>
<h2 id="TensorFlow-核心教程"><a href="#TensorFlow-核心教程" class="headerlink" title="TensorFlow 核心教程"></a>TensorFlow 核心教程</h2><h3 id="导入-TensorFlow-模块"><a href="#导入-TensorFlow-模块" class="headerlink" title="导入 TensorFlow 模块"></a>导入 TensorFlow 模块</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<p> 这使 Python 可以访问 TensorFlow 的所有类、方法和符号。大多数文档假定您已经完成了此操作。</p>
<h3 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h3><p>你可能会想到TensorFlow核心程序由两个独立的部分组成：</p>
<ul>
<li>构建计算图</li>
<li>运行计算图</li>
</ul>
<p>一个计算图是将一系列的 TensorFlow 操作(<code>Operation</code>)排列成一个节点图。让我们建立一个简单的计算图。每个节点以零或更多张量作为输入, 并生成一个张量作为输出。有一种类型的节点是常量。像所有的 TensorFlow 常量一样, 它不需要输入, 并且输出一个它在内部存储的值。我们可以创建两个浮点张量 node1 和 node2 如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">node1 = tf.constant(<span class="number">3.0</span>, dtype=tf.float32)</span><br><span class="line">node2 = tf.constant(<span class="number">4.0</span>) <span class="comment"># also tf.float32 implicitly</span></span><br><span class="line">print(node1, node2)</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Tensor(<span class="string">"Const:0"</span>, shape=(), dtype=float32) Tensor(<span class="string">"Const_1:0"</span>, shape=(), dtype=float32)</span><br></pre></td></tr></table></figure></p>
<p>请注意, 打印节点不会像您预期的那样输出值3.0 和4.0，相反, 它们是在计算时将分别产生3.0 和4.0 的节点，要实际评估节点, 我们必须在一个会话(<code>session</code>)中运行计算图，会话封装了 TensorFlow 运行时的控制和状态。</p>
<p>下面的代码创建一个 <code>session</code> 对象, 然后调用其 run 方法以运行足够的计算图来计算 node1 和 node2。通过在会话(<code>session</code>)中运行计算图, 如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run([node1, node2]))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">3.0</span>, <span class="number">4.0</span>]</span><br></pre></td></tr></table></figure></p>
<p>我们可以通过将张量节点与操作结合起来构建更复杂的计算（操作也是节点）。例如，我们可以添加两个常量节点并生成一个新的图，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line">node3 = tf.add(node1, node2)</span><br><span class="line">print(<span class="string">"node3:"</span>, node3)</span><br><span class="line">print(<span class="string">"sess.run(node3):"</span>, sess.run(node3))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">node3: Tensor(<span class="string">"Add:0"</span>, shape=(), dtype=float32)</span><br><span class="line">sess.run(node3): <span class="number">7.0</span></span><br></pre></td></tr></table></figure></p>
<p>TensorFlow 提供了一种称为 <code>TensorBoard</code> 的实用程序, 可以显示计算图的图片。下面是一个截图, 展示了 <code>TensorBoard</code> 如何直观地显示图:</p>
<p><img src="images/28d118c8.png" alt=""></p>
<p>事实上，这张图并不特别有趣，因为它总是产生一个固定的结果。一个图可以接受外部输入的参数，称为占位符(<code>placeholder</code>)。占位符是稍后提供值的保证。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = tf.placeholder(tf.float32)</span><br><span class="line">b = tf.placeholder(tf.float32)</span><br><span class="line">adder_node = a + b</span><br></pre></td></tr></table></figure>
<p>上面三行有点像函数或 lambda, 我们在其中定义了两个输入参数 (a 和 b), 然后对它们进行操作。我们可以用多个输入来计算这个图, 它使用 feed_dict 参数到 run 方法来给占位符提供具体值:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(sess.run(adder_node, &#123;a: <span class="number">3</span>, b: <span class="number">4.5</span>&#125;))</span><br><span class="line">print(sess.run(adder_node, &#123;a: [<span class="number">1</span>, <span class="number">3</span>], b: [<span class="number">2</span>, <span class="number">4</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">7.5</span></span><br><span class="line">[<span class="number">3.</span> <span class="number">7.</span>]</span><br></pre></td></tr></table></figure></p>
<p>在 TensorBoard 中, 图形如下所示:</p>
<p><img src="images/0d2edff3.png" alt=""></p>
<p>我们可以通过添加另一个操作使计算图更加复杂。例如,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add_and_triple = adder_node * <span class="number">3.</span></span><br><span class="line">print(sess.run(add_and_triple, &#123;a: <span class="number">3</span>, b: <span class="number">4.5</span>&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">22.5</span></span><br></pre></td></tr></table></figure></p>
<p>计算图在 TensorBoard 中如下所示:</p>
<p><img src="images/00ec712b.png" alt=""></p>
<p>在机器学习中, 我们通常需要一个可以接受任意输入的模型, 比如上面的一个。为了使模型训练, 我们需要能够修改图形, 以获得相同的输入新的输出。变量(<code>Variables</code>)允许我们向图中添加训练参数。它们是用类型和初始值构造的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W*x + b</span><br></pre></td></tr></table></figure>
<p>常量在调用 <code>tf.constant</code> 时初始化, 它们的值永远不会改变。相反, 当调用 <code>tf.Variable</code> 时, 变量不会初始化。变量.若要初始化 TensorFlow 程序中的所有变量, 必须显式调用特殊操作, 如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<p>重要的是 <code>init</code> 是一个 TensorFlow 子图, 它是初始化所有的全局变量的句柄。在我们调用  <code>sess.run</code> 之前, 变量是未初始化的。</p>
<p>由于 x 是占位符, 因此我们可以同时对 x 的多个值进行 linear_model 计算, 如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(sess.run(linear_model, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0.</span>         <span class="number">0.3</span>        <span class="number">0.6</span>        <span class="number">0.90000004</span>]</span><br></pre></td></tr></table></figure></p>
<p>我们已经建立了一个模型, 但我们还不知道它有多好。为了评估培训数据的模型, 我们需要一个 y 占位符来提供所需的值, 我们需要写一个损失函数。</p>
<p>损失函数(<code>loss function</code>)用于测量当前模型与所提供数据之间的距离。我们将使用一个标准的线性回归模型, 总结了目前模型和提供数据之间的方差之和。<code>linear_model y</code> 创建一个向量, 其中每个元素都是误差相应的delta。我们调用 <code>tf.square</code> 来给误差做平方计算。然后，然后,我们使用 <code>tf.reduce_sum</code> 来创建一个标量用来计算所有的平方差之和来将所有error实例抽象出来:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line">squared_deltas = tf.square(linear_model - y)</span><br><span class="line">loss = tf.reduce_sum(squared_deltas)</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">23.66</span></span><br></pre></td></tr></table></figure></p>
<p>我们可以通过将 W 和 b 的值重新指派为-1 和1的完美值来手动改进此项。变量初始化的值为 <code>tf.Variable</code> 提供 。可以使用 <code>tf.assign</code> 进行改变。例如，w＝1和B＝1是我们模型的最佳参数。我们可以相应地改变w和b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fixW = tf.assign(W, [<span class="number">-1.</span>])</span><br><span class="line">fixb = tf.assign(b, [<span class="number">1.</span>])</span><br><span class="line">sess.run([fixW, fixb])</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[array([<span class="number">-1.</span>], dtype=float32), array([<span class="number">1.</span>], dtype=float32)]</span><br><span class="line"><span class="number">0.0</span></span><br></pre></td></tr></table></figure></p>
<p>我们猜测 W 和 b 的 “完美” 值, 但机器学习的全部意义是自动找到正确的模型参数。在下一节中, 我们将演示如何完成此操作。</p>
<h2 id="tf-train-API"><a href="#tf-train-API" class="headerlink" title="tf.train API"></a>tf.train API</h2><p>关于机器学习的完整讨论超出了本教程的范围。然而, TensorFlow 提供优化器(<code>optimizers</code>), 慢慢地改变每个变量, 以尽量减少损失函数(<code>loss function</code>)。最简单的优化器是梯度下降(<code>gradient descent</code>)。它根据该变量的损失函数的大小来修正每个变量。一般而言, 手工计算 <code>symbolic derivatives</code> 是单调乏味且容易出错的。因此, TensorFlow 可以自动产生 <code>derivatives</code> , 只给出一个描述的模型使用函数 <code>tf.gradients</code> 。为了简单起见, 优化器(<code>optimizers</code>) 通常为您执行此操作。例如,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess.run(init) <span class="comment"># reset variables to incorrect defaults.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  sess.run(train, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;)</span><br><span class="line"></span><br><span class="line">print(sess.run([W, b]))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[array([<span class="number">-0.9999969</span>], dtype=float32), array([<span class="number">0.9999908</span>], dtype=float32)]</span><br></pre></td></tr></table></figure></p>
<p>现在我们已经完成了实际上的机器学习!虽然这个简单的线性回归模型不需要太多的 <code>TensorFlow core</code> 代码, 但使用更复杂的模型和方法将数据导入到模型中, 这就必须有更多的代码。因此, TensorFlow 为常见的模式、结构和功能(<code>patterns,structures,and functionality</code>)提供了更高级别的抽象(<code>abstractions</code>)。在下一节中, 我们将学习如何使用这些抽象。</p>
<h3 id="完成代码"><a href="#完成代码" class="headerlink" title="完成代码"></a>完成代码</h3><p>已完成的训练线性回归模型如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model parameters</span></span><br><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line"><span class="comment"># Model input and output</span></span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W*x + b</span><br><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_sum(tf.square(linear_model - y)) <span class="comment"># sum of the squares</span></span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training data</span></span><br><span class="line">x_train = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">y_train = [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]</span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init) <span class="comment"># initialize variables with incorrect defaults.</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  sess.run(train, &#123;x: x_train, y: y_train&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate training accuracy</span></span><br><span class="line">curr_W, curr_b, curr_loss = sess.run([W, b, loss], &#123;x: x_train, y: y_train&#125;)</span><br><span class="line">print(<span class="string">"W: %s b: %s loss: %s"</span>%(curr_W, curr_b, curr_loss))</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">W: [<span class="number">-0.9999969</span>] b: [<span class="number">0.9999908</span>] loss: <span class="number">5.6999738e-11</span></span><br></pre></td></tr></table></figure></p>
<p>请注意, 损失是一个非常小的数字 (非常接近零)。如果您运行此程序, 您的损失可能与前面提到的损失完全相同, 因为模型是用伪随机值初始化的。</p>
<p>这个更复杂的程序仍然可以在 TensorBoard 中可视化:</p>
<p><img src="images/c1f79ff6.png" alt=""></p>
<h2 id="tf-estimator"><a href="#tf-estimator" class="headerlink" title="tf.estimator"></a>tf.estimator</h2><p><code>tf.estimator</code> 是一个高级TensorFlow库,用于简化机器学习的机制,其内容包括:</p>
<ul>
<li>训练循环</li>
<li>赋值循环</li>
<li>管理数据集</li>
</ul>
<p><code>tf.estimator</code> 定义了许多常见的模型。</p>
<h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p>请注意使用 <code>tf.estimator</code> 使得线性回归变得多么简单:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># NumPy is often used to load, manipulate and preprocess data.</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features. We only have one numeric feature. There are many</span></span><br><span class="line"><span class="comment"># other types of columns that are more complicated and useful.</span></span><br><span class="line">feature_columns = [tf.feature_column.numeric_column(<span class="string">"x"</span>, shape=[<span class="number">1</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># An estimator is the front end to invoke training (fitting) and evaluation</span></span><br><span class="line"><span class="comment"># (inference). There are many predefined types like linear regression,</span></span><br><span class="line"><span class="comment"># linear classification, and many neural network classifiers and regressors.</span></span><br><span class="line"><span class="comment"># The following code provides an estimator that does linear regression.</span></span><br><span class="line">estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow provides many helper methods to read and set up data sets.</span></span><br><span class="line"><span class="comment"># Here we use two data sets: one for training and one for evaluation</span></span><br><span class="line"><span class="comment"># We have to tell the function how many batches</span></span><br><span class="line"><span class="comment"># of data (num_epochs) we want and how big each batch should be.</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can invoke 1000 training steps by invoking the method and passing the</span></span><br><span class="line"><span class="comment"># training data set.</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br></pre></td></tr></table></figure>
<p>当它运行时，可能会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train metrics: &#123;<span class="string">'average_loss'</span>: <span class="number">1.0863615e-08</span>, <span class="string">'loss'</span>: <span class="number">4.345446e-08</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br><span class="line">eval metrics: &#123;<span class="string">'average_loss'</span>: <span class="number">0.002535033</span>, <span class="string">'loss'</span>: <span class="number">0.010140132</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>请注意, 我们的 eval 数据有更高的损失, 但它仍然接近于零。这意味着我们正在正确学习。</p>
<h3 id="自定义模型"><a href="#自定义模型" class="headerlink" title="自定义模型"></a>自定义模型</h3><p><code>tf.estimator</code> 不会将你禁锢在它预设的模型中。假设我们想要创建一个自定义模型。我们仍然可以通过 <code>tf.estimator</code> 保持高度抽象的数据集,喂养,训练等。为了说明,我们将展示如何用低级TensorFlow API实现自己的等效线性回归模型。</p>
<p>要使用 <code>tf.estimator</code> 定义一个自定义模型。我们需要使用 <code>tf.estimator.Estimator</code>。<code>tf.estimator.LinearRegressor</code> 实际上是 <code>tf.estimator.Estimator</code> 的一个子类。我们只是给 <code>Estimator</code> 提供一个函数 <code>model_fn</code> 来告诉 <code>tf.estimator</code> 怎样定义预测,训练步骤,和损失，而不是生成子类 <code>Estimator</code>。代码如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features, we only have one real-valued feature</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode)</span>:</span></span><br><span class="line">  <span class="comment"># Build a linear model and predict values</span></span><br><span class="line">  W = tf.get_variable(<span class="string">"W"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  b = tf.get_variable(<span class="string">"b"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  y = W*features[<span class="string">'x'</span>] + b</span><br><span class="line">  <span class="comment"># Loss sub-graph</span></span><br><span class="line">  loss = tf.reduce_sum(tf.square(y - labels))</span><br><span class="line">  <span class="comment"># Training sub-graph</span></span><br><span class="line">  global_step = tf.train.get_global_step()</span><br><span class="line">  optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">  train = tf.group(optimizer.minimize(loss),</span><br><span class="line">                   tf.assign_add(global_step, <span class="number">1</span>))</span><br><span class="line">  <span class="comment"># EstimatorSpec connects subgraphs we built to the</span></span><br><span class="line">  <span class="comment"># appropriate functionality.</span></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">      mode=mode,</span><br><span class="line">      predictions=y,</span><br><span class="line">      loss=loss,</span><br><span class="line">      train_op=train)</span><br><span class="line"></span><br><span class="line">estimator = tf.estimator.Estimator(model_fn=model_fn)</span><br><span class="line"><span class="comment"># define our data sets</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7.</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br></pre></td></tr></table></figure>
<p>当它运行时，会输出<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train metrics: &#123;<span class="string">'loss'</span>: <span class="number">1.08032486e-10</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br><span class="line">eval metrics: &#123;<span class="string">'loss'</span>: <span class="number">0.010101897</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>注意，自定义model()函数的内容和低级API的手动循环训练模型十分相似。</p>
<h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>现在您有了TensorFlow的基础知识。我们有几个教程,您可以看看了解更多信息。如果您是初学者的话，请看<a href="/ml/tensorflow/mnist.html">MNIST机器学习入门</a>, 否则看<a href="/ml/tensorflow/deep-mnist.html">深入探索MNIST</a>.</p>

  
</div>

        
      </div>
      <script src="/js/smooth-scroll.min.js"></script>
    

    <!-- main custom script for sidebars, version selects etc. -->
    <script src="/js/css.escape.js"></script>
    <script src="/js/common.js"></script>
    <script src="/js/local_search.js"></script>

    <!-- search -->
    <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <script>
    var path = "/search.xml";
    searchFunc(path, 'local-search-input', 'local-search-result');
    var inputArea       = document.querySelector("#local-search-input");
    inputArea.onclick   = function(){ getSearchFile(); this.onclick = null }
    inputArea.onkeydown = function(){ if(event.keyCode == 13) return false }
    var $resultContent = document.getElementById('local-search-result');
    var BTN = "<i id='local-search-close'>×</i>";
    $resultContent.innerHTML = BTN + "<ul><span class='local-search-empty'>Please wait for 1024 seconds ……<span></ul>";
    </script>

    <!-- fastclick -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js"></script>
    <script>
    document.addEventListener('DOMContentLoaded', function() {
      FastClick.attach(document.body)
    }, false)
    </script>
  </body>
</html>
