

<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <title>TensorFlow运作方式入门 — Itimor's Book</title>
    <meta charset="utf-8">
    <meta name="description" content="Itimor's Book">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    <meta property="og:type" content="article">
    <meta property="og:title" content="TensorFlow运作方式入门 — Itimor's Book">
    <meta property="og:description" content="Itimor's Book">
    <meta property="og:image" content="https://itimor.github.io//images/logo.png">

    <link rel="icon" type="image/png" sizes="32x32" href="/images/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/images/icons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/icons/favicon-16x16.png">
    <link rel="icon" href="/images/logo.png" type="image/png">
      
    <meta name="baidu-site-verification" content="ah99c7kYSG" />
    <meta name="msapplication-TileColor" content="#4fc08d">
    <meta name="theme-color" content="#4fc08d">
    <meta name="msapplication-config" content="browserconfig.xml">


    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- main page styles -->
    <link rel="stylesheet" href="/css/page.css">

    <!-- this needs to be loaded before guide's inline scripts -->
    <script>window.PAGE_TYPE = "tensorflow"</script>

    <!-- ga -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', '', 'itimor.github.io');
      ga('send', 'pageview');
    </script>
  </head>
  <body class="docs">
    <div id="mobile-bar" >
      <a class="menu-button"></a>
      <a class="logo" href="/"></a>
    </div>
    <div id="header">
  <a id="logo" href="/">
   <!-- <img src="/images/logo.png"> -->
    <span>Itimor's Book</span>
  </a>
  <ul id="nav">
    <li>
  <form id="search-form">
    <input type="text" id="local-search-input" class="local-search-input">
    <div id="local-search-result" class="local-search-result"></div>
  </form>
</li>
<li class="nav-dropdown-container learn">
  <a class="nav-link">机器学习</a><span class="arrow"></span>
  <ul class="nav-dropdown">
    <li><ul>
      <li><a href="/ml/tensorflow/" class="nav-link current">Tensorflow</a></li>
      <li><a href="/ml/mllib/" class="nav-link">基础包介绍</a></li>
    </ul></li>
  </ul>
</li>

<li>
  <a href="/about/" class="nav-link team">about</a>
</li>
  </ul>
</div>
    
      <div id="main" class="fix-sidebar">
        
          
  <div class="sidebar">
  <div class="sidebar-inner">
    <ul class="main-menu">
      <li>
  <form id="search-form">
    <input type="text" id="local-search-input" class="local-search-input">
    <div id="local-search-result" class="local-search-result"></div>
  </form>
</li>
<li class="nav-dropdown-container learn">
  <a class="nav-link">机器学习</a><span class="arrow"></span>
  <ul class="nav-dropdown">
    <li><ul>
      <li><a href="/ml/tensorflow/" class="nav-link current">Tensorflow</a></li>
      <li><a href="/ml/mllib/" class="nav-link">基础包介绍</a></li>
    </ul></li>
  </ul>
</li>

<li>
  <a href="/about/" class="nav-link team">about</a>
</li>
    </ul>
    <div class="list">
      <h2>
        
        Tensorflow教程
      </h2>
      <ul class="menu-root">
  
    
    
    
    <li>
      <a href="/ml/tensorflow/index.html" class="sidebar-link">Tensorflow入门</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/mnist.html" class="sidebar-link">MNIST机器学习入门</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/deep-mnist.html" class="sidebar-link">深入探索MNIST</a>
    </li>
  
    
    
    
    <li>
      <a href="/ml/tensorflow/tensorflow101.html" class="sidebar-link current">TensorFlow运作方式入门</a>
    </li>
  
  
</ul>

    </div>
  </div>
</div>


<div class="content tensorflow with-sidebar ">
  
    
  
  
    <h1>TensorFlow运作方式入门</h1>
  
  <p>代码: <a href="Code: tensorflow/examples/tutorials/mnist/" target="_blank" rel="noopener">tensorflow/examples/tutorials/mnist/</a></p>
<p>本篇教程的目的，是向大家展示如何利用TensorFlow使用（经典）MNIST数据集训练并评估一个用于识别手写数字的简易前馈神经网络（feed-forward neural network）。我们的目标读者，是有兴趣使用TensorFlow的资深机器学习人士。</p>
<p>因此，撰写该系列教程并不是为了教大家机器学习领域的基础知识。</p>
<p>在学习本教程之前，请确保您已按照安装TensorFlow教程中的要求，完成了安装。</p>
<h2 id="教程使用的文件"><a href="#教程使用的文件" class="headerlink" title="教程使用的文件"></a>教程使用的文件</h2><p>本教程引用如下文件：</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>目的</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py" target="_blank" rel="noopener">mnist.py</a></td>
<td>构建一个完全连接（fully connected）的MINST模型所需的代码。</td>
</tr>
<tr>
<td><a href="https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/fully_connected_feed.py" target="_blank" rel="noopener">fully_connected_feed.py</a></td>
<td>利用下载的数据集训练构建好的MNIST模型的主要代码，以数据反馈字典（feed dictionary）的形式作为输入模型。</td>
</tr>
</tbody>
</table>
<p>只需要直接运行<code>fully_connected_feed.py</code>文件，就可以开始训练：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python fully_connected_feed.py</span><br></pre></td></tr></table></figure>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>MNIST是机器学习领域的一个经典问题，指的是让机器查看一系列大小为28x28像素的手写数字灰度图像，并判断这些图像代表0-9中的哪一个数字。</p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>在<code>run_training()</code>方法的一开始，<code>input_data.read_data_sets()</code>函数会确保你的本地训练文件夹中，已经下载了正确的数据，然后将这些数据解压并返回一个含有<code>DataSet</code>实例的字典。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data)</span><br></pre></td></tr></table></figure>
<p>注意：<code>fake_data</code>标记是用于单元测试的，读者可以不必理会。</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>目的</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data_sets.train</code></td>
<td>55000个图像和标签（labels），作为主要训练集。</td>
</tr>
<tr>
<td><code>data_sets.validation</code></td>
<td>5000个图像和标签，用于迭代验证训练准确度。</td>
</tr>
<tr>
<td><code>data_sets.test</code></td>
<td>10000个图像和标签，用于最终测试训练准确度（trained accuracy）。</td>
</tr>
</tbody>
</table>
<h3 id="输入与占位符"><a href="#输入与占位符" class="headerlink" title="输入与占位符"></a>输入与占位符</h3><p><code>placeholder_inputs()</code>函数将生成两个<code>tf.placeholder</code>操作，定义传入图表中的shape参数，shape参数中包括<code>batch_size</code>值，后续还会将实际的训练用例传入图表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">images_placeholder = tf.placeholder(tf.float32, shape=(batch_size, mnist.IMAGE_PIXELS))</span><br><span class="line">labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))</span><br></pre></td></tr></table></figure>
<p>在训练循环（training loop）的后续步骤中，传入的整个图像和标签数据集会被切片，以符合每一个操作所设置的<code>batch_size</code>值，占位符操作将会填补以符合这个<code>batch_size</code>值。然后使用<code>feed_dict</code>参数，将数据传入<code>sess.run()</code>函数。</p>
<h2 id="构建图表-（Build-the-Graph）"><a href="#构建图表-（Build-the-Graph）" class="headerlink" title="构建图表 （Build the Graph）"></a>构建图表 （Build the Graph）</h2><p>在为数据创建占位符之后，就可以运行<code>mnist.py</code>文件，经过三阶段的模式函数操作：<code>inference()</code>， <code>loss()</code>，和<code>training()</code>。图表就构建完成了。</p>
<ol>
<li>inference() —— 尽可能地构建好图表，满足促使神经网络向前反馈并做出预测的要求。</li>
<li>loss() —— 往inference图表中添加生成损失（loss）所需要的操作（ops）。</li>
<li>training() —— 往损失图表中添加计算并应用梯度（gradients）所需的操作。</li>
</ol>
<p><img src="images/6725d75a.png" alt=""></p>
<h3 id="推理（Inference）"><a href="#推理（Inference）" class="headerlink" title="推理（Inference）"></a>推理（Inference）</h3><p>inference()函数会尽可能地构建图表，做到返回包含了预测结果（output prediction）的Tensor。</p>
<p>它接受图像占位符为输入，在此基础上借助<code>ReLu</code>(Rectified Linear Units)激活函数，构建一对完全连接层（layers），以及一个有着十个节点（node）、指明了输出logits模型的线性层。</p>
<p>每一层都创建于一个唯一的<code>tf.name_scope</code>之下，创建于该作用域之下的所有元素都将带有其前缀。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'hidden1'</span>):</span><br></pre></td></tr></table></figure>
<p>在定义的作用域中，每一层所使用的权重和偏差都在<code>tf.Variable</code>实例中生成，并且包含了各自期望的shape。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights = tf.Variable(</span><br><span class="line">    tf.truncated_normal([IMAGE_PIXELS, hidden1_units],</span><br><span class="line">                        stddev=<span class="number">1.0</span> / math.sqrt(float(IMAGE_PIXELS))),</span><br><span class="line">    name=<span class="string">'weights'</span>)</span><br><span class="line">biases = tf.Variable(tf.zeros([hidden1_units]),</span><br><span class="line">                     name=<span class="string">'biases'</span>)</span><br></pre></td></tr></table></figure>
<p>例如，当这些层是在<code>hidden1</code>作用域下生成时，赋予权重变量的独特名称将会是”<code>hidden1/weights</code>“。</p>
<p>每个变量在构建时，都会获得初始化操作（initializer ops）。</p>
<p>在这种最常见的情况下，通过<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/truncated_normal" target="_blank" rel="noopener">tf.truncated_normal</a>函数初始化权重变量，给赋予的shape则是一个二维tensor，其中第一个维度代表该层中权重变量所连接（connect from）的单元数量，第二个维度代表该层中权重变量所连接到的（connect to）单元数量。对于名叫hidden1的第一层，相应的维度则是<code>[IMAGE_PIXELS, hidden1_units]</code>，因为权重变量将图像输入连接到了hidden1层。<code>tf.truncated_normal</code>初始函数将根据所得到的均值和标准差，生成一个随机分布。</p>
<p>然后，通过<code>tf.zeros</code>函数初始化偏差变量（biases），确保所有偏差的起始值都是0，而它们的shape则是其在该层中所接到的（connect to）单元数量。</p>
<p>图表的三个主要操作，分别是两个<code>tf.nn.relu</code>操作，它们中嵌入了隐藏层所需的<code>tf.matmul</code>；以及logits模型所需的另外一个<code>tf.matmul</code>。三者依次生成，各自的<code>tf.Variable</code>实例则与输入占位符或下一层的输出tensor所连接。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)</span><br><span class="line">hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)</span><br><span class="line">logits = tf.matmul(hidden2, weights) + biases</span><br></pre></td></tr></table></figure>
<p>最后，程序会返回包含了输出结果的<code>logits</code>Tensor。</p>
<h3 id="损失（Loss）"><a href="#损失（Loss）" class="headerlink" title="损失（Loss）"></a>损失（Loss）</h3><p>loss()函数通过添加所需的损失操作，进一步构建图表。</p>
<p>首先, labels_placeholder 的值被转换为64位整数。然后, 添加一个 <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits" target="_blank" rel="noopener">tf.nn.sparse_softmax_cross_entropy_with_logits</a> op 以自动从 <code>labels_placeholder</code> 生成 1-hot 标签, 并将输出数与推断 <code>inference()</code> 函数与那些1-hot 签进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels = tf.to_int64(labels)</span><br><span class="line">cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">    labels=labels, logits=logits, name=<span class="string">'xentropy'</span>)</span><br></pre></td></tr></table></figure>
<p>然后，使用<code>tf.reduce_mean</code>函数，计算batch维度（第一维度）下交叉熵（cross entropy）的平均值，将将该值作为总损失。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = tf.reduce_mean(cross_entropy, name=<span class="string">'xentropy_mean'</span>)</span><br></pre></td></tr></table></figure>
<p>最后，程序会返回包含了损失值的Tensor。</p>
<blockquote>
<p>注意：交叉熵是信息理论中的概念，可以让我们描述如果基于已有事实，相信神经网络所做的推测最坏会导致什么结果。更多详情，请查阅博文《可视化信息理论》(<a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">http://colah.github.io/posts/2015-09-Visual-Information/</a>)</p>
</blockquote>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p><code>training()</code>函数添加了通过<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="noopener">梯度下降</a>（gradient descent）将损失最小化所需的操作。</p>
<p>首先，该函数从<code>loss()</code>函数中获取损失Tensor，将其交给<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/summary/scalar" target="_blank" rel="noopener">tf.scalar_summary</a>，该 op 用于在与 <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/summary/FileWriter" target="_blank" rel="noopener">tf.summary.FileWriter</a> (见下文) 一起使用时将汇总值（summary values）生成到事件文件（events file）中。在本篇教程中，每次写入汇总值时，它都会释放损失Tensor的当前值（snapshot value）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.scalar_summary(loss.op.name, loss)</span><br></pre></td></tr></table></figure>
<p>接下来，我们实例化一个<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/train/GradientDescentOptimizer" target="_blank" rel="noopener">tf.train.GradientDescentOptimizer</a>，负责按照所要求的学习效率（learning rate）应用梯度下降法（gradients）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure>
<p>之后，我们生成一个变量用于保存全局训练步骤（global training step）的数值，并使用<a href="tf.train.Optimizer.minimize">tf.train.Optimizer.minimize</a>函数更新系统中的三角权重（triangle weights）、增加全局步骤的操作。根据惯例，这个操作被称为 train_op，是TensorFlow会话（session）诱发一个完整训练步骤所必须运行的操作（见下文）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">train_op = optimizer.minimize(loss, global_step=global_step)</span><br></pre></td></tr></table></figure>
<h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>一旦图表构建完毕，就通过<code>fully_connected_feed.py</code>文件中的用户代码进行循环地迭代式训练和评估。</p>
<h3 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h3><p>在<code>run_training()</code>这个函数的一开始，是一个Python语言中的with命令，这个命令表明所有已经构建的操作都要与默认的<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph" target="_blank" rel="noopener">tf.Graph</a>全局实例关联起来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default():</span><br></pre></td></tr></table></figure>
<p><code>tf.Graph</code>实例是一系列可以作为整体执行的操作。TensorFlow的大部分场景只需要依赖默认图表一个实例即可。</p>
<p>利用多个图表的更加复杂的使用场景也是可能的，但是超出了本教程的范围。</p>
<h3 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h3><p>完成全部的构建准备、生成全部所需的操作之后，我们就可以创建一个<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/Session" target="_blank" rel="noopener">tf.Session</a>，用于运行图表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure>
<p>另外，也可以利用with代码块生成<code>Session</code>，限制作用域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br></pre></td></tr></table></figure>
<p>Session函数中没有传入参数，表明该代码将会依附于（如果还没有创建会话，则会创建新的会话）默认的本地会话。</p>
<p>生成会话之后，所有<code>tf.Variable</code>实例都会立即通过调用各自初始化操作中的<a href="tf.Session.run">tf.Session.run</a>函数进行初始化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure>
<p><code>sess.run()</code>方法将会运行图表中与作为参数传入的操作相对应的完整子集。在初次调用时，init操作只包含了变量初始化程序<a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/group" target="_blank" rel="noopener">tf.group</a>。图表的其他部分不会在这里，而是在下面的训练循环运行。</p>
<h3 id="训练循环"><a href="#训练循环" class="headerlink" title="训练循环"></a>训练循环</h3><p>完成会话中变量的初始化之后，就可以开始训练了。</p>
<p>训练的每一步都是通过用户代码控制，而能实现有效训练的最简单循环就是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    sess.run(train_op)</span><br></pre></td></tr></table></figure>
<p>然而，本教程中的例子要更为复杂一点，原因是我们必须把输入的数据根据每一步的情况进行切分，以匹配之前生成的占位符。</p>
<h4 id="向图表提供反馈"><a href="#向图表提供反馈" class="headerlink" title="向图表提供反馈"></a>向图表提供反馈</h4><p>执行每一步时，我们的代码会生成一个反馈字典（feed dictionary），其中包含对应步骤中训练所要使用的例子，这些例子的哈希键就是其所代表的占位符操作。</p>
<p><code>fill_feed_dict</code>函数会查询给定的<code>DataSet</code>，索要下一批次<code>batch_size</code>的图像和标签，与占位符相匹配的Tensor则会包含下一批次的图像和标签。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,</span><br><span class="line">                                               FLAGS.fake_data)</span><br></pre></td></tr></table></figure>
<p>然后，以占位符为哈希键，创建一个Python字典对象，键值则是其代表的反馈Tensor。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feed_dict = &#123;</span><br><span class="line">    images_placeholder: images_feed,</span><br><span class="line">    labels_placeholder: labels_feed,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个字典随后作为<code>feed_dict</code>参数，传入<code>sess.run()</code>函数中，为这一步的训练提供输入样例。</p>
<h4 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h4><p>在运行<code>sess.run</code>函数时，要在代码中明确其需要获取的两个值：<code>[train_op, loss]</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(FLAGS.max_steps):</span><br><span class="line">    feed_dict = fill_feed_dict(data_sets.train,</span><br><span class="line">                               images_placeholder,</span><br><span class="line">                               labels_placeholder)</span><br><span class="line">    _, loss_value = sess.run([train_op, loss],</span><br><span class="line">                             feed_dict=feed_dict)</span><br></pre></td></tr></table></figure>
<p>因为要获取这两个值，<code>sess.run()</code>会返回一个有两个元素的元组。其中每一个Tensor对象，对应了返回的元组中的numpy数组，而这些数组中包含了当前这步训练中对应Tensor的值。由于<code>train_op</code>并不会产生输出，其在返回的元祖中的对应元素就是<code>None</code>，所以会被抛弃。但是，如果模型在训练中出现偏差，<code>loss</code>Tensor的值可能会变成NaN，所以我们要获取它的值，并记录下来。</p>
<p>假设训练一切正常，没有出现NaN，训练循环会每隔100个训练步骤，就打印一行简单的状态文本，告知用户当前的训练状态。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'Step %d: loss = %.2f (%.3f sec)'</span> % (step, loss_value, duration)</span><br></pre></td></tr></table></figure>
<h4 id="状态可视化"><a href="#状态可视化" class="headerlink" title="状态可视化"></a>状态可视化</h4><p>为了释放<a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/summaries_and_tensorboard.html" target="_blank" rel="noopener">TensorBoard</a>所使用的事件文件（events file），所有的即时数据（在这里只有一个）都要在图表构建阶段合并至一个操作（op）中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary = tf.summary.merge_all()</span><br></pre></td></tr></table></figure>
<p>在创建好会话（session）之后，可以实例化一个<code>tf.train.SummaryWriter</code>，用于写入包含了图表本身和即时数据具体值的事件文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary_writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)</span><br></pre></td></tr></table></figure>
<p>最后，每次运行<code>summary</code>时，都会往事件文件中写入最新的即时数据，函数的输出会传入事件文件读写器（writer）的<code>add_summary()</code>函数。。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">summary_str = sess.run(summary, feed_dict=feed_dict)</span><br><span class="line">summary_writer.add_summary(summary_str, step)</span><br></pre></td></tr></table></figure>
<p>事件文件写入完毕之后，可以就训练文件夹打开一个TensorBoard，查看即时数据的情况。</p>
<p><img src="images/7e0bb7f7.png" alt=""></p>
<p>注意：了解更多如何构建并运行TensorBoard的信息，请查看相关教程<a href="https://www.tensorflow.org/versions/master/get_started/summaries_and_tensorboard" target="_blank" rel="noopener">Tensorboard：训练过程可视化</a>。</p>
<h4 id="保存检查点（checkpoint）"><a href="#保存检查点（checkpoint）" class="headerlink" title="保存检查点（checkpoint）"></a>保存检查点（checkpoint）</h4><p>为了得到可以用来后续恢复模型以进一步训练或评估的检查点文件（checkpoint file），我们实例化一个<code>tf.train.Saver</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br></pre></td></tr></table></figure>
<p>在训练循环中，将定期调用<code>tf.train.Saver.save</code>方法，向训练文件夹中写入包含了当前所有可训练变量值得检查点文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver.save(sess, FLAGS.train_dir, global_step=step)</span><br></pre></td></tr></table></figure>
<p>这样，我们以后就可以使用<code>saver.restore()</code>方法，重载模型的参数，继续训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">saver.restore(sess, FLAGS.train_dir)</span><br></pre></td></tr></table></figure>
<h2 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h2><p>每隔一千个训练步骤，我们的代码会尝试使用训练数据集与测试数据集，对模型进行评估。<code>do_eval</code>函数会被调用三次，分别使用训练数据集、验证数据集合测试数据集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(<span class="string">'Training Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.train)</span><br><span class="line">print(<span class="string">'Validation Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.validation)</span><br><span class="line">print(<span class="string">'Test Data Eval:'</span>)</span><br><span class="line">do_eval(sess,</span><br><span class="line">        eval_correct,</span><br><span class="line">        images_placeholder,</span><br><span class="line">        labels_placeholder,</span><br><span class="line">        data_sets.test)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，更复杂的使用场景通常是，先隔绝 <code>data_sets.test</code> 测试数据集，只有在大量的超参数优化调整（hyperparameter tuning）之后才进行检查。但是，由于MNIST问题比较简单，我们在这里一次性评估所有的数据。</p>
</blockquote>
<h3 id="构建评估图表（Eval-Graph）"><a href="#构建评估图表（Eval-Graph）" class="headerlink" title="构建评估图表（Eval Graph）"></a>构建评估图表（Eval Graph）</h3><p>在进入训练循环之前，我们应该先调用<code>mnist.py</code>文件中的<code>evaluation</code>函数，传入的logits和标签参数要与<code>loss()</code>的一致。这样做事为了先构建Eval操作。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_correct = mnist.evaluation(logits, labels_placeholder)</span><br></pre></td></tr></table></figure></p>
<p><code>evaluation</code>函数会生成<code>tf.nn.in_top_k</code> 操作，如果在K个最有可能的预测中可以发现真的标签，那么这个操作就会将模型输出标记为正确。在本文中，我们把<code>K</code>的值设置为1，也就是只有在预测是真的标签时，才判定它是正确的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_correct = tf.nn.in_top_k(logits, labels, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="评估图表的输出（Eval-Output）"><a href="#评估图表的输出（Eval-Output）" class="headerlink" title="评估图表的输出（Eval Output）"></a>评估图表的输出（Eval Output）</h3><p>之后，我们可以创建一个循环，往其中添加<code>feed_dict</code>，并在调用<code>sess.run()</code>函数时传入<code>eval_correct</code>操作，目的就是用给定的数据集评估模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(steps_per_epoch):</span><br><span class="line">    feed_dict = fill_feed_dict(data_set,</span><br><span class="line">                               images_placeholder,</span><br><span class="line">                               labels_placeholder)</span><br><span class="line">    true_count += sess.run(eval_correct, feed_dict=feed_dict)</span><br></pre></td></tr></table></figure>
<p><code>true_count</code>变量会累加所有<code>in_top_k</code>操作判定为正确的预测之和。接下来，只需要将正确测试的总数，除以例子总数，就可以得出准确率了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">precision = true_count / num_examples</span><br><span class="line">print(<span class="string">'  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f'</span> %</span><br><span class="line">      (num_examples, true_count, precision))</span><br></pre></td></tr></table></figure>
  
</div>

        
      </div>
      <script src="/js/smooth-scroll.min.js"></script>
    

    <!-- main custom script for sidebars, version selects etc. -->
    <script src="/js/css.escape.js"></script>
    <script src="/js/common.js"></script>
    <script src="/js/local_search.js"></script>

    <!-- search -->
    <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <script>
    var path = "/search.xml";
    searchFunc(path, 'local-search-input', 'local-search-result');
    var inputArea       = document.querySelector("#local-search-input");
    inputArea.onclick   = function(){ getSearchFile(); this.onclick = null }
    inputArea.onkeydown = function(){ if(event.keyCode == 13) return false }
    var $resultContent = document.getElementById('local-search-result');
    var BTN = "<i id='local-search-close'>×</i>";
    $resultContent.innerHTML = BTN + "<ul><span class='local-search-empty'>Please wait for 1024 seconds ……<span></ul>";
    </script>

    <!-- fastclick -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js"></script>
    <script>
    document.addEventListener('DOMContentLoaded', function() {
      FastClick.attach(document.body)
    }, false)
    </script>
  </body>
</html>
